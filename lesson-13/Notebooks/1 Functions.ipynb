{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82b2d70-528e-4d70-82d8-e09e3c6a9ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971c7adb-21bc-45c6-9739-19d3542686c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4caaef5-6fb9-4333-8b72-ed1115989f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "24/09/09 20:04:05 INFO SparkContext: Running Spark version 3.5.0\n",
      "24/09/09 20:04:05 INFO SparkContext: OS info Linux, 6.8.0-40-generic, amd64\n",
      "24/09/09 20:04:05 INFO SparkContext: Java version 11.0.24\n",
      "24/09/09 20:04:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/09 20:04:06 INFO ResourceUtils: ==============================================================\n",
      "24/09/09 20:04:06 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/09/09 20:04:06 INFO ResourceUtils: ==============================================================\n",
      "24/09/09 20:04:06 INFO SparkContext: Submitted application: Functions\n",
      "24/09/09 20:04:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/09/09 20:04:06 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/09/09 20:04:06 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/09/09 20:04:06 INFO SecurityManager: Changing view acls to: vadim\n",
      "24/09/09 20:04:06 INFO SecurityManager: Changing modify acls to: vadim\n",
      "24/09/09 20:04:06 INFO SecurityManager: Changing view acls groups to: \n",
      "24/09/09 20:04:06 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/09/09 20:04:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vadim; groups with view permissions: EMPTY; users with modify permissions: vadim; groups with modify permissions: EMPTY\n",
      "24/09/09 20:04:06 INFO Utils: Successfully started service 'sparkDriver' on port 46205.\n",
      "24/09/09 20:04:06 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/09/09 20:04:06 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/09/09 20:04:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/09/09 20:04:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/09/09 20:04:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/09/09 20:04:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0bc4f8ec-501c-4519-b950-26c1a56f71cd\n",
      "24/09/09 20:04:06 INFO MemoryStore: MemoryStore started with capacity 4.5 GiB\n",
      "24/09/09 20:04:06 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/09/09 20:04:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/09/09 20:04:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/09/09 20:04:07 INFO Executor: Starting executor ID driver on host ubuntu\n",
      "24/09/09 20:04:07 INFO Executor: OS info Linux, 6.8.0-40-generic, amd64\n",
      "24/09/09 20:04:07 INFO Executor: Java version 11.0.24\n",
      "24/09/09 20:04:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "24/09/09 20:04:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1c20c112 for default.\n",
      "24/09/09 20:04:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37259.\n",
      "24/09/09 20:04:07 INFO NettyBlockTransferService: Server created on ubuntu:37259\n",
      "24/09/09 20:04:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/09/09 20:04:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ubuntu, 37259, None)\n",
      "24/09/09 20:04:07 INFO BlockManagerMasterEndpoint: Registering block manager ubuntu:37259 with 4.5 GiB RAM, BlockManagerId(driver, ubuntu, 37259, None)\n",
      "24/09/09 20:04:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ubuntu, 37259, None)\n",
      "24/09/09 20:04:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ubuntu, 37259, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@5dfe391f\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"Functions\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb82f43-9e6f-4bcb-80d7-40a361767774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/09/09 20:04:09 INFO SharedState: Warehouse path is 'file:/home/vadim/workspace/Spark/UDF%20UDAF/spark-warehouse'.\n",
      "24/09/09 20:04:10 INFO CodeGenerator: Code generated in 265.717015 ms\n",
      "24/09/09 20:04:12 INFO CodeGenerator: Code generated in 12.354238 ms\n",
      "24/09/09 20:04:12 INFO CodeGenerator: Code generated in 19.293655 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 4 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 1, 300, 1551903533),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 2, 120, 1551903567),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"CA\" ,4, 75, 1551903599),\n",
    "    (\"Holden\", \"Karau\", \"CA\" , 6, 37, 1551904299),\n",
    "    (\"Ginni\", \"Rometty\", \"NY\", 7, 91, 1551916792),\n",
    "    (\"Holden\", \"Karau\", \"CA\", 4, 153, 1552876129)\n",
    ").toDF(\"firstName\", \"lastName\", \"state\", \"quantity\", \"revenue\", \"timestamp\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4511b195-2d41-41db-9ea5-5dc623f47cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- quantity: integer (nullable = false)\n",
      " |-- revenue: integer (nullable = false)\n",
      " |-- timestamp: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531fae9-0baa-4ede-93d1-8b701ac68783",
   "metadata": {},
   "source": [
    "## Array Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5812952-39e8-40b9-83f1-ceb87f32df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:13 INFO CodeGenerator: Code generated in 10.971148 ms\n",
      "24/09/09 20:04:13 INFO CodeGenerator: Code generated in 17.347162 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2 = data\n",
    "                .withColumn(\"k2v\", array($\"firstName\", $\"lastName\", $\"state\"))\n",
    "                .withColumn(\"k2n\", array(lit(\"FirstName\"), lit(\"LastName\"), lit(\"State\")))\n",
    "\n",
    "datak2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1659d289-550c-4ba4-ab16-617ae6da25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:14 INFO CodeGenerator: Code generated in 8.273841 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datak2.where(array_contains($\"k2v\", \"CA\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337eedf-cec3-4d0f-88c5-0327ee36f616",
   "metadata": {},
   "source": [
    "## Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ea9f77-080a-4d62-8fc4-e37c0206f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:14 INFO CodeGenerator: Code generated in 9.318766 ms\n",
      "24/09/09 20:04:14 INFO CodeGenerator: Code generated in 14.418347 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2m\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2m = data.withColumn(\"k2m\", map(lit(\"FirstName\"), $\"firstName\", lit(\"LastName\"), $\"lastName\", lit(\"State\"), $\"state\"))\n",
    "\n",
    "datak2m.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d653367c-af17-47d8-9302-3b20f694a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:15 INFO CodeGenerator: Code generated in 10.377395 ms\n",
      "24/09/09 20:04:15 INFO CodeGenerator: Code generated in 15.076361 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2ma\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 7 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2ma = datak2.withColumn(\"k2m\", map_from_arrays($\"k2n\", $\"k2v\"))\n",
    "\n",
    "datak2ma.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174009f8-f995-43c8-857d-4f7afbcea3e4",
   "metadata": {},
   "source": [
    "## Date and Timestamp Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc68f1e7-2fc4-4c8f-819a-148308e6406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |recordTimestamp    |current                   |\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|2019-03-06 23:18:53|2024-09-09 20:04:15.764363|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|2019-03-06 23:19:27|2024-09-09 20:04:15.764363|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|2019-03-06 23:19:59|2024-09-09 20:04:15.764363|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|2019-03-06 23:31:39|2024-09-09 20:04:15.764363|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|2019-03-07 02:59:52|2024-09-09 20:04:15.764363|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|2019-03-18 05:28:49|2024-09-09 20:04:15.764363|\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatat\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datat = data\n",
    "                .withColumn(\"recordTimestamp\", to_timestamp($\"timestamp\"))\n",
    "                .withColumn(\"current\", current_timestamp())\n",
    "\n",
    "datat.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb7c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- quantity: integer (nullable = false)\n",
      " |-- revenue: integer (nullable = false)\n",
      " |-- timestamp: integer (nullable = false)\n",
      " |-- recordTimestamp: timestamp (nullable = false)\n",
      " |-- current: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datat.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923bf8a5-a4da-48d2-99ea-faf664a7a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:16 INFO CodeGenerator: Code generated in 8.259 ms\n",
      "24/09/09 20:04:16 INFO CodeGenerator: Code generated in 9.496741 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+----------------------------------+\n",
      "|recordTimestamp    |current                   |datediff(current, recordTimestamp)|\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "|2019-03-06 23:18:53|2024-09-09 20:04:16.281041|2014                              |\n",
      "|2019-03-06 23:19:27|2024-09-09 20:04:16.281041|2014                              |\n",
      "|2019-03-06 23:19:59|2024-09-09 20:04:16.281041|2014                              |\n",
      "|2019-03-06 23:31:39|2024-09-09 20:04:16.281041|2014                              |\n",
      "|2019-03-07 02:59:52|2024-09-09 20:04:16.281041|2013                              |\n",
      "|2019-03-18 05:28:49|2024-09-09 20:04:16.281041|2002                              |\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datat.select($\"recordTimestamp\", $\"current\", datediff($\"current\", $\"recordTimestamp\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dd5f2-9d23-45ba-97dd-cb869fe5331f",
   "metadata": {},
   "source": [
    "## JSON Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9e0c1c-83c3-4d85-b8d0-790fb4b3c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |k2j                                                          |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"CA\"}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |{\"FirstName\":\"Ginni\",\"LastName\":\"Rometty\",\"State\":\"NY\"}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2j\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2j = datak2m.withColumn(\"k2j\", to_json($\"k2m\"))\n",
    "\n",
    "datak2j.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c5e15-5439-4cc5-8e9c-d4ca908cca3c",
   "metadata": {},
   "source": [
    "## Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d80a2d-6636-4841-be49-646816ecbd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data2 = data\n",
    "                .withColumn(\"a1\", array(lit(1), lit(2), lit(3), lit(4), lit(5)))\n",
    "                .withColumn(\"a2\", lit((1 to 5).toArray))\n",
    "\n",
    "data2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886eb9f8-e8e1-451e-9c0f-74a393acb4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:17 INFO CodeGenerator: Code generated in 5.66023 ms\n",
      "24/09/09 20:04:18 INFO CodeGenerator: Code generated in 28.554711 ms\n",
      "24/09/09 20:04:18 INFO CodeGenerator: Code generated in 15.779777 ms\n",
      "24/09/09 20:04:18 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Got job 0 (show at cell14.sc:1) with 1 output partitions\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Final stage: ResultStage 0 (show at cell14.sc:1)\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "24/09/09 20:04:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.5 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ubuntu:37259 (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7955 bytes) \n",
      "24/09/09 20:04:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/09/09 20:04:18 INFO CodeGenerator: Code generated in 17.480983 ms\n",
      "24/09/09 20:04:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1706 bytes result sent to driver\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 215 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:18 INFO DAGScheduler: ResultStage 0 (show at cell14.sc:1) finished in 0,433 s\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Job 0 finished: show at cell14.sc:1, took 0,489067 s\n",
      "24/09/09 20:04:18 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Got job 1 (show at cell14.sc:1) with 4 output partitions\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Final stage: ResultStage 1 (show at cell14.sc:1)\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "24/09/09 20:04:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ubuntu:37259 (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7955 bytes) \n",
      "24/09/09 20:04:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7955 bytes) \n",
      "24/09/09 20:04:18 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7947 bytes) \n",
      "24/09/09 20:04:18 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7947 bytes) \n",
      "24/09/09 20:04:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "24/09/09 20:04:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/09/09 20:04:18 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
      "24/09/09 20:04:18 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
      "24/09/09 20:04:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1656 bytes result sent to driver\n",
      "24/09/09 20:04:18 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1695 bytes result sent to driver\n",
      "24/09/09 20:04:18 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1650 bytes result sent to driver\n",
      "24/09/09 20:04:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 34 ms on ubuntu (executor driver) (1/4)\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 48 ms on ubuntu (executor driver) (2/4)\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 46 ms on ubuntu (executor driver) (3/4)\n",
      "24/09/09 20:04:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 56 ms on ubuntu (executor driver) (4/4)\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:18 INFO DAGScheduler: ResultStage 1 (show at cell14.sc:1) finished in 0,075 s\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/09/09 20:04:18 INFO DAGScheduler: Job 1 finished: show at cell14.sc:1, took 0,090960 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |dummy|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.withColumn(\"dummy\", explode($\"a1\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9904a83-620a-4537-9dd4-8a0dac8092be",
   "metadata": {},
   "source": [
    "## Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351a5cea-7668-4b03-a961-86658da77882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mwindowSpec\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@2e691295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val windowSpec = Window.partitionBy(\"firstName\", \"lastName\").orderBy(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334205e6-b9b8-4dd2-b1df-8e801acd5833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:19 INFO CodeGenerator: Code generated in 7.922256 ms\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Registering RDD 5 (show at cell16.sc:3) as input to shuffle 0\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Got map stage job 2 (show at cell16.sc:3) with 6 output partitions\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (show at cell16.sc:3)\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell16.sc:3), which has no missing parents\n",
      "24/09/09 20:04:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ubuntu:37259 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:19 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/09/09 20:04:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 6 tasks resource profile 0\n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:19 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
      "24/09/09 20:04:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)\n",
      "24/09/09 20:04:19 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)\n",
      "24/09/09 20:04:19 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)\n",
      "24/09/09 20:04:19 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)\n",
      "24/09/09 20:04:19 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 12.403128 ms\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1868 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1868 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1868 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 135 ms on ubuntu (executor driver) (1/6)\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 147 ms on ubuntu (executor driver) (2/6)\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 156 ms on ubuntu (executor driver) (3/6)\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 143 ms on ubuntu (executor driver) (4/6)\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 148 ms on ubuntu (executor driver) (5/6)\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 162 ms on ubuntu (executor driver) (6/6)\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:20 INFO DAGScheduler: ShuffleMapStage 2 (show at cell16.sc:3) finished in 0,215 s\n",
      "24/09/09 20:04:20 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/09/09 20:04:20 INFO DAGScheduler: running: Set()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: waiting: Set()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: failed: Set()\n",
      "24/09/09 20:04:20 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 13.311777 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 12.662818 ms\n",
      "24/09/09 20:04:20 INFO SparkContext: Starting job: show at cell16.sc:3\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Got job 3 (show at cell16.sc:3) with 1 output partitions\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Final stage: ResultStage 4 (show at cell16.sc:3)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at show at cell16.sc:3), which has no missing parents\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 30.9 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ubuntu:37259 (size: 14.1 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/09/09 20:04:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 17.632804 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 7.189472 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 14.303266 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 7.264115 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 7.442716 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 4.953047 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 4.654925 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 6.499492 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 9.247296 ms\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 4914 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 294 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:20 INFO DAGScheduler: ResultStage 4 (show at cell16.sc:3) finished in 0,338 s\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Job 3 finished: show at cell16.sc:3, took 0,358661 s\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Registering RDD 12 (show at cell16.sc:3) as input to shuffle 1\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Got map stage job 4 (show at cell16.sc:3) with 1 output partitions\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (show at cell16.sc:3)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at show at cell16.sc:3), which has no missing parents\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ubuntu:37259 (size: 14.6 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7604 bytes) \n",
      "24/09/09 20:04:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 4441 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 57 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:20 INFO DAGScheduler: ShuffleMapStage 6 (show at cell16.sc:3) finished in 0,081 s\n",
      "24/09/09 20:04:20 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/09/09 20:04:20 INFO DAGScheduler: running: Set()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: waiting: Set()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: failed: Set()\n",
      "24/09/09 20:04:20 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 16.409557 ms\n",
      "24/09/09 20:04:20 INFO SparkContext: Starting job: show at cell16.sc:3\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Got job 5 (show at cell16.sc:3) with 1 output partitions\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Final stage: ResultStage 9 (show at cell16.sc:3)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[15] at show at cell16.sc:3), which has no missing parents\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.9 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ubuntu:37259 (size: 16.5 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[15] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 13) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/09/09 20:04:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 13)\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Getting 1 (613.0 B) non-empty blocks including 1 (613.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/09/09 20:04:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/09/09 20:04:20 INFO CodeGenerator: Code generated in 17.26976 ms\n",
      "24/09/09 20:04:20 INFO Executor: Finished task 0.0 in stage 9.0 (TID 13). 6099 bytes result sent to driver\n",
      "24/09/09 20:04:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 13) in 46 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:20 INFO DAGScheduler: ResultStage 9 (show at cell16.sc:3) finished in 0,072 s\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "24/09/09 20:04:20 INFO DAGScheduler: Job 5 finished: show at cell16.sc:3, took 0,087143 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataw\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataw = data.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "dataw.orderBy(\"firstName\", \"lastName\", \"state\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76bdfc0e-b90a-49ea-85bc-9859ffce6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 8.154024 ms\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Registering RDD 19 (show at cell17.sc:1) as input to shuffle 2\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Got map stage job 6 (show at cell17.sc:1) with 6 output partitions\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at cell17.sc:1)\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[19] at show at cell17.sc:1), which has no missing parents\n",
      "24/09/09 20:04:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 23.2 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ubuntu:37259 (size: 11.1 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[19] at show at cell17.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/09/09 20:04:21 INFO TaskSchedulerImpl: Adding task set 10.0 with 6 tasks resource profile 0\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 14) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 15) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 16) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ubuntu:37259 in memory (size: 14.6 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 17) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 18) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 19) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ubuntu:37259 in memory (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 3.0 in stage 10.0 (TID 17)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 2.0 in stage 10.0 (TID 16)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 4.0 in stage 10.0 (TID 18)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 1.0 in stage 10.0 (TID 15)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 14)\n",
      "24/09/09 20:04:21 INFO Executor: Running task 5.0 in stage 10.0 (TID 19)\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ubuntu:37259 in memory (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ubuntu:37259 in memory (size: 16.5 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 31.028668 ms\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ubuntu:37259 in memory (size: 14.1 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ubuntu:37259 in memory (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 14). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 3.0 in stage 10.0 (TID 17). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 14) in 137 ms on ubuntu (executor driver) (1/6)\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 2.0 in stage 10.0 (TID 16). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 17) in 132 ms on ubuntu (executor driver) (2/6)\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 1.0 in stage 10.0 (TID 15). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 16) in 137 ms on ubuntu (executor driver) (3/6)\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 5.0 in stage 10.0 (TID 19). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 4.0 in stage 10.0 (TID 18). 2206 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 15) in 142 ms on ubuntu (executor driver) (4/6)\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 18) in 143 ms on ubuntu (executor driver) (5/6)\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 19) in 141 ms on ubuntu (executor driver) (6/6)\n",
      "24/09/09 20:04:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:21 INFO DAGScheduler: ShuffleMapStage 10 (show at cell17.sc:1) finished in 0,229 s\n",
      "24/09/09 20:04:21 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/09/09 20:04:21 INFO DAGScheduler: running: Set()\n",
      "24/09/09 20:04:21 INFO DAGScheduler: waiting: Set()\n",
      "24/09/09 20:04:21 INFO DAGScheduler: failed: Set()\n",
      "24/09/09 20:04:21 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 12.03292 ms\n",
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 9.568785 ms\n",
      "24/09/09 20:04:21 INFO SparkContext: Starting job: show at cell17.sc:1\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Got job 7 (show at cell17.sc:1) with 1 output partitions\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Final stage: ResultStage 12 (show at cell17.sc:1)\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[25] at show at cell17.sc:1), which has no missing parents\n",
      "24/09/09 20:04:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 35.8 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ubuntu:37259 (size: 15.6 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[25] at show at cell17.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:21 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 20) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/09/09 20:04:21 INFO Executor: Running task 0.0 in stage 12.0 (TID 20)\n",
      "24/09/09 20:04:21 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/09/09 20:04:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 14.623233 ms\n",
      "24/09/09 20:04:21 INFO CodeGenerator: Code generated in 9.877758 ms\n",
      "24/09/09 20:04:21 INFO Executor: Finished task 0.0 in stage 12.0 (TID 20). 4994 bytes result sent to driver\n",
      "24/09/09 20:04:21 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 20) in 63 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:21 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:21 INFO DAGScheduler: ResultStage 12 (show at cell17.sc:1) finished in 0,080 s\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "24/09/09 20:04:21 INFO DAGScheduler: Job 7 finished: show at cell17.sc:1, took 0,098175 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.where($\"row_number\" === 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea680ad-9eb7-443d-bc29-b54a343b2141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:04:22 INFO DAGScheduler: Registering RDD 28 (show at cell18.sc:1) as input to shuffle 3\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Got map stage job 8 (show at cell18.sc:1) with 6 output partitions\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at cell18.sc:1)\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[28] at show at cell18.sc:1), which has no missing parents\n",
      "24/09/09 20:04:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 8.9 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ubuntu:37259 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[28] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/09/09 20:04:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 6 tasks resource profile 0\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 21) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 22) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 23) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 24) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 25) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 26) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/09/09 20:04:22 INFO Executor: Running task 1.0 in stage 13.0 (TID 22)\n",
      "24/09/09 20:04:22 INFO Executor: Running task 2.0 in stage 13.0 (TID 23)\n",
      "24/09/09 20:04:22 INFO Executor: Running task 4.0 in stage 13.0 (TID 25)\n",
      "24/09/09 20:04:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 21)\n",
      "24/09/09 20:04:22 INFO Executor: Running task 3.0 in stage 13.0 (TID 24)\n",
      "24/09/09 20:04:22 INFO Executor: Running task 5.0 in stage 13.0 (TID 26)\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 21). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 2.0 in stage 13.0 (TID 23). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 1.0 in stage 13.0 (TID 22). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 23) in 36 ms on ubuntu (executor driver) (1/6)\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 21) in 46 ms on ubuntu (executor driver) (2/6)\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 3.0 in stage 13.0 (TID 24). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 22) in 51 ms on ubuntu (executor driver) (3/6)\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 4.0 in stage 13.0 (TID 25). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 5.0 in stage 13.0 (TID 26). 1825 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 24) in 50 ms on ubuntu (executor driver) (4/6)\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 25) in 56 ms on ubuntu (executor driver) (5/6)\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 26) in 56 ms on ubuntu (executor driver) (6/6)\n",
      "24/09/09 20:04:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:22 INFO DAGScheduler: ShuffleMapStage 13 (show at cell18.sc:1) finished in 0,089 s\n",
      "24/09/09 20:04:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/09/09 20:04:22 INFO DAGScheduler: running: Set()\n",
      "24/09/09 20:04:22 INFO DAGScheduler: waiting: Set()\n",
      "24/09/09 20:04:22 INFO DAGScheduler: failed: Set()\n",
      "24/09/09 20:04:22 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 16.40793 ms\n",
      "24/09/09 20:04:22 INFO SparkContext: Starting job: show at cell18.sc:1\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Got job 9 (show at cell18.sc:1) with 1 output partitions\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Final stage: ResultStage 15 (show at cell18.sc:1)\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[33] at show at cell18.sc:1), which has no missing parents\n",
      "24/09/09 20:04:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 34.9 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ubuntu:37259 (size: 15.5 KiB, free: 4.5 GiB)\n",
      "24/09/09 20:04:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/09 20:04:22 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 27) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/09/09 20:04:22 INFO Executor: Running task 0.0 in stage 15.0 (TID 27)\n",
      "24/09/09 20:04:22 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/09/09 20:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 7.765137 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 5.627254 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 8.15605 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 6.184638 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 5.288673 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 5.947183 ms\n",
      "24/09/09 20:04:22 INFO CodeGenerator: Code generated in 9.700194 ms\n",
      "24/09/09 20:04:22 INFO Executor: Finished task 0.0 in stage 15.0 (TID 27). 4721 bytes result sent to driver\n",
      "24/09/09 20:04:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 27) in 106 ms on ubuntu (executor driver) (1/1)\n",
      "24/09/09 20:04:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "24/09/09 20:04:22 INFO DAGScheduler: ResultStage 15 (show at cell18.sc:1) finished in 0,129 s\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/09 20:04:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "24/09/09 20:04:22 INFO DAGScheduler: Job 9 finished: show at cell18.sc:1, took 0,144970 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|revenue2|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|      91|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|      37|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|      37|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|      75|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|      75|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|      75|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.withColumn(\"revenue2\", nth_value($\"revenue\", 1).over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c7042-3b2c-4d32-a8cb-8aa8e6c5d252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
