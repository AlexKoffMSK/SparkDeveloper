{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82b2d70-528e-4d70-82d8-e09e3c6a9ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971c7adb-21bc-45c6-9739-19d3542686c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4caaef5-6fb9-4333-8b72-ed1115989f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "24/06/13 14:37:40 INFO SparkContext: Running Spark version 3.5.0\n",
      "24/06/13 14:37:40 INFO SparkContext: OS info Linux, 6.5.0-35-generic, amd64\n",
      "24/06/13 14:37:40 INFO SparkContext: Java version 11.0.23\n",
      "24/06/13 14:37:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/13 14:37:40 INFO ResourceUtils: ==============================================================\n",
      "24/06/13 14:37:40 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/06/13 14:37:40 INFO ResourceUtils: ==============================================================\n",
      "24/06/13 14:37:40 INFO SparkContext: Submitted application: Functions\n",
      "24/06/13 14:37:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/06/13 14:37:40 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/06/13 14:37:40 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/06/13 14:37:40 INFO SecurityManager: Changing view acls to: vadim\n",
      "24/06/13 14:37:40 INFO SecurityManager: Changing modify acls to: vadim\n",
      "24/06/13 14:37:40 INFO SecurityManager: Changing view acls groups to: \n",
      "24/06/13 14:37:40 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/06/13 14:37:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vadim; groups with view permissions: EMPTY; users with modify permissions: vadim; groups with modify permissions: EMPTY\n",
      "24/06/13 14:37:40 INFO Utils: Successfully started service 'sparkDriver' on port 38983.\n",
      "24/06/13 14:37:41 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/06/13 14:37:41 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/06/13 14:37:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/06/13 14:37:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/06/13 14:37:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/06/13 14:37:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a91b3430-7f31-4dd4-98c5-a002e79e696a\n",
      "24/06/13 14:37:41 INFO MemoryStore: MemoryStore started with capacity 4.5 GiB\n",
      "24/06/13 14:37:41 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/06/13 14:37:41 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/06/13 14:37:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/06/13 14:37:41 INFO Executor: Starting executor ID driver on host ubuntu\n",
      "24/06/13 14:37:41 INFO Executor: OS info Linux, 6.5.0-35-generic, amd64\n",
      "24/06/13 14:37:41 INFO Executor: Java version 11.0.23\n",
      "24/06/13 14:37:41 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "24/06/13 14:37:41 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@12873cfb for default.\n",
      "24/06/13 14:37:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43247.\n",
      "24/06/13 14:37:41 INFO NettyBlockTransferService: Server created on ubuntu:43247\n",
      "24/06/13 14:37:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/06/13 14:37:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ubuntu, 43247, None)\n",
      "24/06/13 14:37:41 INFO BlockManagerMasterEndpoint: Registering block manager ubuntu:43247 with 4.5 GiB RAM, BlockManagerId(driver, ubuntu, 43247, None)\n",
      "24/06/13 14:37:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ubuntu, 43247, None)\n",
      "24/06/13 14:37:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ubuntu, 43247, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@11d59b70\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"Functions\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb82f43-9e6f-4bcb-80d7-40a361767774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:37:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/06/13 14:37:50 INFO SharedState: Warehouse path is 'file:/home/vadim/workspace/Spark/UDF%20UDAF/Notebooks/spark-warehouse'.\n",
      "24/06/13 14:37:51 INFO CodeGenerator: Code generated in 189.876564 ms\n",
      "24/06/13 14:37:52 INFO CodeGenerator: Code generated in 7.696383 ms\n",
      "24/06/13 14:37:52 INFO CodeGenerator: Code generated in 15.236597 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 4 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 1, 300, 1551903533),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 2, 120, 1551903567),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"CA\" ,4, 75, 1551903599),\n",
    "    (\"Holden\", \"Karau\", \"CA\" , 6, 37, 1551904299),\n",
    "    (\"Ginni\", \"Rometty\", \"NY\", 7, 91, 1551916792),\n",
    "    (\"Holden\", \"Karau\", \"CA\", 4, 153, 1552876129)\n",
    ").toDF(\"firstName\", \"lastName\", \"state\", \"quantity\", \"revenue\", \"timestamp\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4511b195-2d41-41db-9ea5-5dc623f47cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- quantity: integer (nullable = false)\n",
      " |-- revenue: integer (nullable = false)\n",
      " |-- timestamp: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531fae9-0baa-4ede-93d1-8b701ac68783",
   "metadata": {},
   "source": [
    "## Array Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5812952-39e8-40b9-83f1-ceb87f32df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:38:05 INFO CodeGenerator: Code generated in 7.455793 ms\n",
      "24/06/13 14:38:05 INFO CodeGenerator: Code generated in 15.854865 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2 = data\n",
    "                .withColumn(\"k2v\", array($\"firstName\", $\"lastName\", $\"state\"))\n",
    "                .withColumn(\"k2n\", array(lit(\"FirstName\"), lit(\"LastName\"), lit(\"State\")))\n",
    "\n",
    "datak2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1659d289-550c-4ba4-ab16-617ae6da25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:38:20 INFO CodeGenerator: Code generated in 6.975848 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datak2.where(array_contains($\"k2v\", \"CA\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337eedf-cec3-4d0f-88c5-0327ee36f616",
   "metadata": {},
   "source": [
    "## Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ea9f77-080a-4d62-8fc4-e37c0206f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:38:27 INFO CodeGenerator: Code generated in 6.051562 ms\n",
      "24/06/13 14:38:27 INFO CodeGenerator: Code generated in 13.19775 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2m\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2m = data.withColumn(\"k2m\", map(lit(\"FirstName\"), $\"firstName\", lit(\"LastName\"), $\"lastName\", lit(\"State\"), $\"state\"))\n",
    "\n",
    "datak2m.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d653367c-af17-47d8-9302-3b20f694a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:38:47 INFO CodeGenerator: Code generated in 6.009049 ms\n",
      "24/06/13 14:38:47 INFO CodeGenerator: Code generated in 10.531083 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2ma\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 7 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2ma = datak2.withColumn(\"k2m\", map_from_arrays($\"k2n\", $\"k2v\"))\n",
    "\n",
    "datak2ma.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174009f8-f995-43c8-857d-4f7afbcea3e4",
   "metadata": {},
   "source": [
    "## Date and Timestamp Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc68f1e7-2fc4-4c8f-819a-148308e6406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |recordTimestamp    |current                |\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|2019-03-06 23:18:53|2024-06-13 14:38:52.817|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|2019-03-06 23:19:27|2024-06-13 14:38:52.817|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|2019-03-06 23:19:59|2024-06-13 14:38:52.817|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|2019-03-06 23:31:39|2024-06-13 14:38:52.817|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|2019-03-07 02:59:52|2024-06-13 14:38:52.817|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|2019-03-18 05:28:49|2024-06-13 14:38:52.817|\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatat\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datat = data\n",
    "                .withColumn(\"recordTimestamp\", to_timestamp($\"timestamp\"))\n",
    "                .withColumn(\"current\", current_timestamp())\n",
    "\n",
    "datat.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923bf8a5-a4da-48d2-99ea-faf664a7a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:39:16 INFO CodeGenerator: Code generated in 5.403803 ms\n",
      "24/06/13 14:39:16 INFO CodeGenerator: Code generated in 7.524116 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+----------------------------------+\n",
      "|recordTimestamp    |current                   |datediff(current, recordTimestamp)|\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "|2019-03-06 23:18:53|2024-06-13 14:39:16.803107|1926                              |\n",
      "|2019-03-06 23:19:27|2024-06-13 14:39:16.803107|1926                              |\n",
      "|2019-03-06 23:19:59|2024-06-13 14:39:16.803107|1926                              |\n",
      "|2019-03-06 23:31:39|2024-06-13 14:39:16.803107|1926                              |\n",
      "|2019-03-07 02:59:52|2024-06-13 14:39:16.803107|1925                              |\n",
      "|2019-03-18 05:28:49|2024-06-13 14:39:16.803107|1914                              |\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datat.select($\"recordTimestamp\", $\"current\", datediff($\"current\", $\"recordTimestamp\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dd5f2-9d23-45ba-97dd-cb869fe5331f",
   "metadata": {},
   "source": [
    "## JSON Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9e0c1c-83c3-4d85-b8d0-790fb4b3c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |k2j                                                          |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"CA\"}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |{\"FirstName\":\"Ginni\",\"LastName\":\"Rometty\",\"State\":\"NY\"}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2j\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2j = datak2m.withColumn(\"k2j\", to_json($\"k2m\"))\n",
    "\n",
    "datak2j.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c5e15-5439-4cc5-8e9c-d4ca908cca3c",
   "metadata": {},
   "source": [
    "## Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d80a2d-6636-4841-be49-646816ecbd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data2 = data\n",
    "                .withColumn(\"a1\", array(lit(1), lit(2), lit(3), lit(4), lit(5)))\n",
    "                .withColumn(\"a2\", lit((1 to 5).toArray))\n",
    "\n",
    "data2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886eb9f8-e8e1-451e-9c0f-74a393acb4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:39:41 INFO CodeGenerator: Code generated in 3.338502 ms\n",
      "24/06/13 14:39:41 INFO CodeGenerator: Code generated in 16.620851 ms\n",
      "24/06/13 14:39:41 INFO CodeGenerator: Code generated in 12.023876 ms\n",
      "24/06/13 14:39:41 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "24/06/13 14:39:41 INFO DAGScheduler: Got job 0 (show at cell14.sc:1) with 1 output partitions\n",
      "24/06/13 14:39:41 INFO DAGScheduler: Final stage: ResultStage 0 (show at cell14.sc:1)\n",
      "24/06/13 14:39:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/13 14:39:41 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:39:41 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "24/06/13 14:39:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.5 KiB, free 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ubuntu:43247 (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7955 bytes) \n",
      "24/06/13 14:39:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/06/13 14:39:42 INFO CodeGenerator: Code generated in 12.329162 ms\n",
      "24/06/13 14:39:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1706 bytes result sent to driver\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 142 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:39:42 INFO DAGScheduler: ResultStage 0 (show at cell14.sc:1) finished in 0,294 s\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Job 0 finished: show at cell14.sc:1, took 0,333455 s\n",
      "24/06/13 14:39:42 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Got job 1 (show at cell14.sc:1) with 4 output partitions\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Final stage: ResultStage 1 (show at cell14.sc:1)\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "24/06/13 14:39:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ubuntu:43247 (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:39:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7955 bytes) \n",
      "24/06/13 14:39:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7955 bytes) \n",
      "24/06/13 14:39:42 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7947 bytes) \n",
      "24/06/13 14:39:42 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7947 bytes) \n",
      "24/06/13 14:39:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/06/13 14:39:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "24/06/13 14:39:42 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
      "24/06/13 14:39:42 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
      "24/06/13 14:39:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 19 ms on ubuntu (executor driver) (1/4)\n",
      "24/06/13 14:39:42 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1652 bytes result sent to driver\n",
      "24/06/13 14:39:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1656 bytes result sent to driver\n",
      "24/06/13 14:39:42 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1650 bytes result sent to driver\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 21 ms on ubuntu (executor driver) (2/4)\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 24 ms on ubuntu (executor driver) (3/4)\n",
      "24/06/13 14:39:42 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 23 ms on ubuntu (executor driver) (4/4)\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:39:42 INFO DAGScheduler: ResultStage 1 (show at cell14.sc:1) finished in 0,038 s\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:39:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/06/13 14:39:42 INFO DAGScheduler: Job 1 finished: show at cell14.sc:1, took 0,043510 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |dummy|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.withColumn(\"dummy\", explode($\"a1\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9904a83-620a-4537-9dd4-8a0dac8092be",
   "metadata": {},
   "source": [
    "## Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "351a5cea-7668-4b03-a961-86658da77882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:40:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ubuntu:43247 in memory (size: 5.2 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ubuntu:43247 in memory (size: 5.2 KiB, free: 4.5 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mwindowSpec\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@566e7ba1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val windowSpec  = Window.partitionBy(\"firstName\", \"lastName\").orderBy(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "334205e6-b9b8-4dd2-b1df-8e801acd5833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 4.821635 ms\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Registering RDD 5 (show at cell17.sc:3) as input to shuffle 0\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Got map stage job 2 (show at cell17.sc:3) with 6 output partitions\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (show at cell17.sc:3)\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell17.sc:3), which has no missing parents\n",
      "24/06/13 14:40:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ubuntu:43247 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell17.sc:3) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/06/13 14:40:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 6 tasks resource profile 0\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:39 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)\n",
      "24/06/13 14:40:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)\n",
      "24/06/13 14:40:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
      "24/06/13 14:40:39 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)\n",
      "24/06/13 14:40:39 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)\n",
      "24/06/13 14:40:39 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 8.391924 ms\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1868 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1868 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1825 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1825 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1825 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1825 bytes result sent to driver\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 96 ms on ubuntu (executor driver) (1/6)\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 98 ms on ubuntu (executor driver) (2/6)\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 97 ms on ubuntu (executor driver) (3/6)\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 96 ms on ubuntu (executor driver) (4/6)\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 96 ms on ubuntu (executor driver) (5/6)\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 96 ms on ubuntu (executor driver) (6/6)\n",
      "24/06/13 14:40:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:39 INFO DAGScheduler: ShuffleMapStage 2 (show at cell17.sc:3) finished in 0,132 s\n",
      "24/06/13 14:40:39 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/06/13 14:40:39 INFO DAGScheduler: running: Set()\n",
      "24/06/13 14:40:39 INFO DAGScheduler: waiting: Set()\n",
      "24/06/13 14:40:39 INFO DAGScheduler: failed: Set()\n",
      "24/06/13 14:40:39 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 10.221218 ms\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 8.32155 ms\n",
      "24/06/13 14:40:39 INFO SparkContext: Starting job: show at cell17.sc:3\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Got job 3 (show at cell17.sc:3) with 1 output partitions\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Final stage: ResultStage 4 (show at cell17.sc:3)\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at show at cell17.sc:3), which has no missing parents\n",
      "24/06/13 14:40:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 30.9 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ubuntu:43247 (size: 14.1 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at show at cell17.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:40:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:40:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/06/13 14:40:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)\n",
      "24/06/13 14:40:39 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/06/13 14:40:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 6.857675 ms\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 6.719311 ms\n",
      "24/06/13 14:40:39 INFO CodeGenerator: Code generated in 6.126341 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 4.742227 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 4.559283 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 3.405104 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 4.101432 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 3.714965 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 5.56545 ms\n",
      "24/06/13 14:40:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 4871 bytes result sent to driver\n",
      "24/06/13 14:40:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 194 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:40 INFO DAGScheduler: ResultStage 4 (show at cell17.sc:3) finished in 0,209 s\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Job 3 finished: show at cell17.sc:3, took 0,223527 s\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Registering RDD 12 (show at cell17.sc:3) as input to shuffle 1\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Got map stage job 4 (show at cell17.sc:3) with 1 output partitions\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (show at cell17.sc:3)\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[12] at show at cell17.sc:3), which has no missing parents\n",
      "24/06/13 14:40:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ubuntu:43247 (size: 14.6 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[12] at show at cell17.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:40:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7604 bytes) \n",
      "24/06/13 14:40:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)\n",
      "24/06/13 14:40:40 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/06/13 14:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/06/13 14:40:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 4441 bytes result sent to driver\n",
      "24/06/13 14:40:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 38 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:40 INFO DAGScheduler: ShuffleMapStage 6 (show at cell17.sc:3) finished in 0,058 s\n",
      "24/06/13 14:40:40 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/06/13 14:40:40 INFO DAGScheduler: running: Set()\n",
      "24/06/13 14:40:40 INFO DAGScheduler: waiting: Set()\n",
      "24/06/13 14:40:40 INFO DAGScheduler: failed: Set()\n",
      "24/06/13 14:40:40 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 13.242981 ms\n",
      "24/06/13 14:40:40 INFO SparkContext: Starting job: show at cell17.sc:3\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Got job 5 (show at cell17.sc:3) with 1 output partitions\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Final stage: ResultStage 9 (show at cell17.sc:3)\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[15] at show at cell17.sc:3), which has no missing parents\n",
      "24/06/13 14:40:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.9 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ubuntu:43247 (size: 16.5 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[15] at show at cell17.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:40:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 13) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/06/13 14:40:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 13)\n",
      "24/06/13 14:40:40 INFO ShuffleBlockFetcherIterator: Getting 1 (613.0 B) non-empty blocks including 1 (613.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/06/13 14:40:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/06/13 14:40:40 INFO CodeGenerator: Code generated in 13.106828 ms\n",
      "24/06/13 14:40:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 13). 6142 bytes result sent to driver\n",
      "24/06/13 14:40:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 13) in 31 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:40 INFO DAGScheduler: ResultStage 9 (show at cell17.sc:3) finished in 0,045 s\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "24/06/13 14:40:40 INFO DAGScheduler: Job 5 finished: show at cell17.sc:3, took 0,049993 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataw\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataw = data.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "dataw.orderBy(\"firstName\", \"lastName\", \"state\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76bdfc0e-b90a-49ea-85bc-9859ffce6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 8.811348 ms\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Registering RDD 19 (show at cell18.sc:1) as input to shuffle 2\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Got map stage job 6 (show at cell18.sc:1) with 6 output partitions\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at cell18.sc:1)\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[19] at show at cell18.sc:1), which has no missing parents\n",
      "24/06/13 14:40:57 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 23.2 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ubuntu:43247 (size: 11.1 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[19] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/06/13 14:40:57 INFO TaskSchedulerImpl: Adding task set 10.0 with 6 tasks resource profile 0\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 14) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 15) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 16) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 17) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 18) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 19) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:40:57 INFO Executor: Running task 2.0 in stage 10.0 (TID 16)\n",
      "24/06/13 14:40:57 INFO Executor: Running task 0.0 in stage 10.0 (TID 14)\n",
      "24/06/13 14:40:57 INFO Executor: Running task 5.0 in stage 10.0 (TID 19)\n",
      "24/06/13 14:40:57 INFO Executor: Running task 4.0 in stage 10.0 (TID 18)\n",
      "24/06/13 14:40:57 INFO Executor: Running task 3.0 in stage 10.0 (TID 17)\n",
      "24/06/13 14:40:57 INFO Executor: Running task 1.0 in stage 10.0 (TID 15)\n",
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 12.177351 ms\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 3.0 in stage 10.0 (TID 17). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 17) in 48 ms on ubuntu (executor driver) (1/6)\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 5.0 in stage 10.0 (TID 19). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 19) in 54 ms on ubuntu (executor driver) (2/6)\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 0.0 in stage 10.0 (TID 14). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 14) in 61 ms on ubuntu (executor driver) (3/6)\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 4.0 in stage 10.0 (TID 18). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 18) in 59 ms on ubuntu (executor driver) (4/6)\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 1.0 in stage 10.0 (TID 15). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 15) in 63 ms on ubuntu (executor driver) (5/6)\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 2.0 in stage 10.0 (TID 16). 2206 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 16) in 70 ms on ubuntu (executor driver) (6/6)\n",
      "24/06/13 14:40:57 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:57 INFO DAGScheduler: ShuffleMapStage 10 (show at cell18.sc:1) finished in 0,094 s\n",
      "24/06/13 14:40:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/06/13 14:40:57 INFO DAGScheduler: running: Set()\n",
      "24/06/13 14:40:57 INFO DAGScheduler: waiting: Set()\n",
      "24/06/13 14:40:57 INFO DAGScheduler: failed: Set()\n",
      "24/06/13 14:40:57 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 10.402925 ms\n",
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 8.986777 ms\n",
      "24/06/13 14:40:57 INFO SparkContext: Starting job: show at cell18.sc:1\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Got job 7 (show at cell18.sc:1) with 1 output partitions\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Final stage: ResultStage 12 (show at cell18.sc:1)\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[25] at show at cell18.sc:1), which has no missing parents\n",
      "24/06/13 14:40:57 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 35.8 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ubuntu:43247 (size: 15.6 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:40:57 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[25] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:40:57 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 20) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/06/13 14:40:57 INFO Executor: Running task 0.0 in stage 12.0 (TID 20)\n",
      "24/06/13 14:40:57 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/06/13 14:40:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 8.6484 ms\n",
      "24/06/13 14:40:57 INFO CodeGenerator: Code generated in 9.089379 ms\n",
      "24/06/13 14:40:57 INFO Executor: Finished task 0.0 in stage 12.0 (TID 20). 4994 bytes result sent to driver\n",
      "24/06/13 14:40:57 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 20) in 44 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:40:57 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:40:57 INFO DAGScheduler: ResultStage 12 (show at cell18.sc:1) finished in 0,054 s\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:40:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "24/06/13 14:40:57 INFO DAGScheduler: Job 7 finished: show at cell18.sc:1, took 0,061760 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.where($\"row_number\" === 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea680ad-9eb7-443d-bc29-b54a343b2141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 14:41:03 INFO DAGScheduler: Registering RDD 28 (show at cell19.sc:1) as input to shuffle 3\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Got map stage job 8 (show at cell19.sc:1) with 6 output partitions\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at cell19.sc:1)\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[28] at show at cell19.sc:1), which has no missing parents\n",
      "24/06/13 14:41:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 8.9 KiB, free 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ubuntu:43247 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[28] at show at cell19.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/06/13 14:41:03 INFO TaskSchedulerImpl: Adding task set 13.0 with 6 tasks resource profile 0\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 21) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 22) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 23) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7848 bytes) \n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 24) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 25) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 26) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7840 bytes) \n",
      "24/06/13 14:41:03 INFO Executor: Running task 2.0 in stage 13.0 (TID 23)\n",
      "24/06/13 14:41:03 INFO Executor: Running task 4.0 in stage 13.0 (TID 25)\n",
      "24/06/13 14:41:03 INFO Executor: Running task 3.0 in stage 13.0 (TID 24)\n",
      "24/06/13 14:41:03 INFO Executor: Running task 5.0 in stage 13.0 (TID 26)\n",
      "24/06/13 14:41:03 INFO Executor: Running task 0.0 in stage 13.0 (TID 21)\n",
      "24/06/13 14:41:03 INFO Executor: Running task 1.0 in stage 13.0 (TID 22)\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 2.0 in stage 13.0 (TID 23). 1868 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 23) in 34 ms on ubuntu (executor driver) (1/6)\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 5.0 in stage 13.0 (TID 26). 1868 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 26) in 33 ms on ubuntu (executor driver) (2/6)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ubuntu:43247 in memory (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 0.0 in stage 13.0 (TID 21). 1868 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 4.0 in stage 13.0 (TID 25). 1868 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 1.0 in stage 13.0 (TID 22). 1825 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 3.0 in stage 13.0 (TID 24). 1868 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 21) in 42 ms on ubuntu (executor driver) (3/6)\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 22) in 44 ms on ubuntu (executor driver) (4/6)\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 25) in 43 ms on ubuntu (executor driver) (5/6)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ubuntu:43247 in memory (size: 15.6 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 24) in 45 ms on ubuntu (executor driver) (6/6)\n",
      "24/06/13 14:41:03 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:41:03 INFO DAGScheduler: ShuffleMapStage 13 (show at cell19.sc:1) finished in 0,056 s\n",
      "24/06/13 14:41:03 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/06/13 14:41:03 INFO DAGScheduler: running: Set()\n",
      "24/06/13 14:41:03 INFO DAGScheduler: waiting: Set()\n",
      "24/06/13 14:41:03 INFO DAGScheduler: failed: Set()\n",
      "24/06/13 14:41:03 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ubuntu:43247 in memory (size: 14.6 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ubuntu:43247 in memory (size: 14.1 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ubuntu:43247 in memory (size: 11.1 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ubuntu:43247 in memory (size: 16.5 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 10.328299 ms\n",
      "24/06/13 14:41:03 INFO SparkContext: Starting job: show at cell19.sc:1\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Got job 9 (show at cell19.sc:1) with 1 output partitions\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Final stage: ResultStage 15 (show at cell19.sc:1)\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Missing parents: List()\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[33] at show at cell19.sc:1), which has no missing parents\n",
      "24/06/13 14:41:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 34.9 KiB, free 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ubuntu:43247 (size: 15.5 KiB, free: 4.5 GiB)\n",
      "24/06/13 14:41:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[33] at show at cell19.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/06/13 14:41:03 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 27) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/06/13 14:41:03 INFO Executor: Running task 0.0 in stage 15.0 (TID 27)\n",
      "24/06/13 14:41:03 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/06/13 14:41:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 6.335657 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 4.450927 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 6.365614 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 4.593993 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 5.261089 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 4.020875 ms\n",
      "24/06/13 14:41:03 INFO CodeGenerator: Code generated in 8.227227 ms\n",
      "24/06/13 14:41:03 INFO Executor: Finished task 0.0 in stage 15.0 (TID 27). 4751 bytes result sent to driver\n",
      "24/06/13 14:41:03 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 27) in 75 ms on ubuntu (executor driver) (1/1)\n",
      "24/06/13 14:41:03 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "24/06/13 14:41:03 INFO DAGScheduler: ResultStage 15 (show at cell19.sc:1) finished in 0,085 s\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/06/13 14:41:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "24/06/13 14:41:03 INFO DAGScheduler: Job 9 finished: show at cell19.sc:1, took 0,090126 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|revenue2|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|    NULL|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|     153|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|     153|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|    NULL|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|     300|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|     300|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.withColumn(\"revenue2\", nth_value($\"revenue\", 2).over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c7042-3b2c-4d32-a8cb-8aa8e6c5d252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
