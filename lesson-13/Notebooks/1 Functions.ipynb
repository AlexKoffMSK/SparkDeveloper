{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a82b2d70-528e-4d70-82d8-e09e3c6a9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/19 11:37:07 INFO BlockManagerInfo: Removed broadcast_47_piece0 on ubuntu:43381 in memory (size: 12.1 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:07 INFO BlockManagerInfo: Removed broadcast_46_piece0 on ubuntu:43381 in memory (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:07 INFO BlockManagerInfo: Removed broadcast_45_piece0 on ubuntu:43381 in memory (size: 12.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:07 INFO BlockManagerInfo: Removed broadcast_44_piece0 on ubuntu:43381 in memory (size: 8.0 KiB, free: 4.5 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "971c7adb-21bc-45c6-9739-19d3542686c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4caaef5-6fb9-4333-8b72-ed1115989f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@2f364fff\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"Functions\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7fb82f43-9e6f-4bcb-80d7-40a361767774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 4 more fields]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 1, 300, 1551903533),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 2, 120, 1551903567),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"CA\" ,4, 75, 1551903599),\n",
    "    (\"Holden\", \"Karau\", \"CA\" , 6, 37, 1551904299),\n",
    "    (\"Ginni\", \"Rometty\", \"NY\", 7, 91, 1551916792),\n",
    "    (\"Holden\", \"Karau\", \"CA\", 4, 153, 1552876129)\n",
    ").toDF(\"firstName\", \"lastName\", \"state\", \"quantity\", \"revenue\", \"timestamp\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4511b195-2d41-41db-9ea5-5dc623f47cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- quantity: integer (nullable = false)\n",
      " |-- revenue: integer (nullable = false)\n",
      " |-- timestamp: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531fae9-0baa-4ede-93d1-8b701ac68783",
   "metadata": {},
   "source": [
    "## Array Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5812952-39e8-40b9-83f1-ceb87f32df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2 = data\n",
    "                .withColumn(\"k2v\", array($\"firstName\", $\"lastName\", $\"state\"))\n",
    "                .withColumn(\"k2n\", array(lit(\"FirstName\"), lit(\"LastName\"), lit(\"State\")))\n",
    "\n",
    "datak2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1659d289-550c-4ba4-ab16-617ae6da25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datak2.where(array_contains($\"k2v\", \"CA\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337eedf-cec3-4d0f-88c5-0327ee36f616",
   "metadata": {},
   "source": [
    "## Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4ea9f77-080a-4d62-8fc4-e37c0206f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2m\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2m = data.withColumn(\"k2m\", map(lit(\"FirstName\"), $\"firstName\", lit(\"LastName\"), $\"lastName\", lit(\"State\"), $\"state\"))\n",
    "\n",
    "datak2m.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d653367c-af17-47d8-9302-3b20f694a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2ma\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 7 more fields]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2ma = datak2.withColumn(\"k2m\", map_from_arrays($\"k2n\", $\"k2v\"))\n",
    "\n",
    "datak2ma.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174009f8-f995-43c8-857d-4f7afbcea3e4",
   "metadata": {},
   "source": [
    "## Date and Timestamp Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc68f1e7-2fc4-4c8f-819a-148308e6406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |recordTimestamp    |current                   |\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|2019-03-06 23:18:53|2024-02-19 11:37:10.114016|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|2019-03-06 23:19:27|2024-02-19 11:37:10.114016|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|2019-03-06 23:19:59|2024-02-19 11:37:10.114016|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|2019-03-06 23:31:39|2024-02-19 11:37:10.114016|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|2019-03-07 02:59:52|2024-02-19 11:37:10.114016|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|2019-03-18 05:28:49|2024-02-19 11:37:10.114016|\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatat\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datat = data\n",
    "                .withColumn(\"recordTimestamp\", to_timestamp($\"timestamp\"))\n",
    "                .withColumn(\"current\", current_timestamp())\n",
    "\n",
    "datat.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "923bf8a5-a4da-48d2-99ea-faf664a7a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+----------------------------------+\n",
      "|recordTimestamp    |current                   |datediff(current, recordTimestamp)|\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "|2019-03-06 23:18:53|2024-02-19 11:37:10.420038|1811                              |\n",
      "|2019-03-06 23:19:27|2024-02-19 11:37:10.420038|1811                              |\n",
      "|2019-03-06 23:19:59|2024-02-19 11:37:10.420038|1811                              |\n",
      "|2019-03-06 23:31:39|2024-02-19 11:37:10.420038|1811                              |\n",
      "|2019-03-07 02:59:52|2024-02-19 11:37:10.420038|1810                              |\n",
      "|2019-03-18 05:28:49|2024-02-19 11:37:10.420038|1799                              |\n",
      "+-------------------+--------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datat.select($\"recordTimestamp\", $\"current\", datediff($\"current\", $\"recordTimestamp\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dd5f2-9d23-45ba-97dd-cb869fe5331f",
   "metadata": {},
   "source": [
    "## JSON Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c9e0c1c-83c3-4d85-b8d0-790fb4b3c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |k2j                                                          |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"CA\"}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |{\"FirstName\":\"Ginni\",\"LastName\":\"Rometty\",\"State\":\"NY\"}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2j\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2j = datak2m.withColumn(\"k2j\", to_json($\"k2m\"))\n",
    "\n",
    "datak2j.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c5e15-5439-4cc5-8e9c-d4ca908cca3c",
   "metadata": {},
   "source": [
    "## Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8d80a2d-6636-4841-be49-646816ecbd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data2 = data\n",
    "                .withColumn(\"a1\", array(lit(1), lit(2), lit(3), lit(4), lit(5)))\n",
    "                .withColumn(\"a2\", lit((1 to 5).toArray))\n",
    "\n",
    "data2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "886eb9f8-e8e1-451e-9c0f-74a393acb4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/19 11:37:11 INFO SparkContext: Starting job: show at cell80.sc:1\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got job 48 (show at cell80.sc:1) with 1 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ResultStage 76 (show at cell80.sc:1)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[170] at show at cell80.sc:1), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 13.7 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on ubuntu:43381 (size: 5.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[170] at show at cell80.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 140) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 8099 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 76.0 (TID 140)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 76.0 (TID 140). 1709 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 140) in 5 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ResultStage 76 (show at cell80.sc:1) finished in 0,009 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 48 finished: show at cell80.sc:1, took 0,010869 s\n",
      "24/02/19 11:37:11 INFO SparkContext: Starting job: show at cell80.sc:1\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got job 49 (show at cell80.sc:1) with 4 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ResultStage 77 (show at cell80.sc:1)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[170] at show at cell80.sc:1), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 13.7 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on ubuntu:43381 (size: 5.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 77 (MapPartitionsRDD[170] at show at cell80.sc:1) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 77.0 with 4 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 141) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 8099 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 142) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 8099 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 143) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 8091 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 144) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 8091 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 77.0 (TID 141)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 2.0 in stage 77.0 (TID 143)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 1.0 in stage 77.0 (TID 142)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 3.0 in stage 77.0 (TID 144)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 77.0 (TID 141). 1709 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 141) in 6 ms on ubuntu (executor driver) (1/4)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 1.0 in stage 77.0 (TID 142). 1702 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 3.0 in stage 77.0 (TID 144). 1696 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 2.0 in stage 77.0 (TID 143). 1698 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 142) in 7 ms on ubuntu (executor driver) (2/4)\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 144) in 8 ms on ubuntu (executor driver) (3/4)\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 143) in 8 ms on ubuntu (executor driver) (4/4)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ResultStage 77 (show at cell80.sc:1) finished in 0,015 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 49 finished: show at cell80.sc:1, took 0,018615 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |dummy|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.withColumn(\"dummy\", explode($\"a1\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9904a83-620a-4537-9dd4-8a0dac8092be",
   "metadata": {},
   "source": [
    "## Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "351a5cea-7668-4b03-a961-86658da77882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mwindowSpec\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@42962cf6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val windowSpec  = Window.partitionBy(\"firstName\", \"lastName\").orderBy(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "334205e6-b9b8-4dd2-b1df-8e801acd5833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/19 11:37:11 INFO BlockManagerInfo: Removed broadcast_48_piece0 on ubuntu:43381 in memory (size: 5.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Removed broadcast_49_piece0 on ubuntu:43381 in memory (size: 5.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Registering RDD 173 (show at cell82.sc:3) as input to shuffle 20\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got map stage job 50 (show at cell82.sc:3) with 6 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ShuffleMapStage 78 (show at cell82.sc:3)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[173] at show at cell82.sc:3), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 9.2 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on ubuntu:43381 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[173] at show at cell82.sc:3) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 78.0 with 6 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 145) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 146) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 147) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 148) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 149) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 150) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 2.0 in stage 78.0 (TID 147)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 78.0 (TID 145)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 1.0 in stage 78.0 (TID 146)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 5.0 in stage 78.0 (TID 150)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 4.0 in stage 78.0 (TID 149)\n",
      "24/02/19 11:37:11 INFO Executor: Running task 3.0 in stage 78.0 (TID 148)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 2.0 in stage 78.0 (TID 147). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 147) in 10 ms on ubuntu (executor driver) (1/6)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 3.0 in stage 78.0 (TID 148). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 1.0 in stage 78.0 (TID 146). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 5.0 in stage 78.0 (TID 150). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 148) in 14 ms on ubuntu (executor driver) (2/6)\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 146) in 16 ms on ubuntu (executor driver) (3/6)\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 150) in 16 ms on ubuntu (executor driver) (4/6)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 78.0 (TID 145). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 145) in 18 ms on ubuntu (executor driver) (5/6)\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 4.0 in stage 78.0 (TID 149). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 149) in 19 ms on ubuntu (executor driver) (6/6)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ShuffleMapStage 78 (show at cell82.sc:3) finished in 0,024 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/19 11:37:11 INFO DAGScheduler: running: HashSet()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: waiting: HashSet()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: failed: HashSet()\n",
      "24/02/19 11:37:11 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/02/19 11:37:11 INFO SparkContext: Starting job: show at cell82.sc:3\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got job 51 (show at cell82.sc:3) with 1 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ResultStage 80 (show at cell82.sc:3)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[179] at show at cell82.sc:3), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 24.8 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on ubuntu:43381 (size: 11.2 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[179] at show at cell82.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 151) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 80.0 (TID 151)\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 80.0 (TID 151). 4960 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 151) in 11 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ResultStage 80 (show at cell82.sc:3) finished in 0,016 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 51 finished: show at cell82.sc:3, took 0,018664 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Registering RDD 180 (show at cell82.sc:3) as input to shuffle 21\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got map stage job 52 (show at cell82.sc:3) with 1 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (show at cell82.sc:3)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[180] at show at cell82.sc:3), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 25.8 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on ubuntu:43381 (size: 11.6 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[180] at show at cell82.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 152) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7684 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 82.0 (TID 152)\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 82.0 (TID 152). 4530 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 152) in 27 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ShuffleMapStage 82 (show at cell82.sc:3) finished in 0,036 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/19 11:37:11 INFO DAGScheduler: running: HashSet()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: waiting: HashSet()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: failed: HashSet()\n",
      "24/02/19 11:37:11 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/02/19 11:37:11 INFO SparkContext: Starting job: show at cell82.sc:3\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Got job 53 (show at cell82.sc:3) with 1 output partitions\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Final stage: ResultStage 85 (show at cell82.sc:3)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[183] at show at cell82.sc:3), which has no missing parents\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 31.3 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on ubuntu:43381 (size: 13.0 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:11 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[183] at show at cell82.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 153) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/02/19 11:37:11 INFO Executor: Running task 0.0 in stage 85.0 (TID 153)\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Getting 1 (613.0 B) non-empty blocks including 1 (613.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/02/19 11:37:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/19 11:37:11 INFO Executor: Finished task 0.0 in stage 85.0 (TID 153). 6188 bytes result sent to driver\n",
      "24/02/19 11:37:11 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 153) in 8 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:11 INFO DAGScheduler: ResultStage 85 (show at cell82.sc:3) finished in 0,012 s\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "24/02/19 11:37:11 INFO DAGScheduler: Job 53 finished: show at cell82.sc:3, took 0,014471 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataw\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataw = data.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "dataw.orderBy(\"firstName\", \"lastName\", \"state\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76bdfc0e-b90a-49ea-85bc-9859ffce6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/19 11:37:12 INFO DAGScheduler: Registering RDD 187 (show at cell83.sc:1) as input to shuffle 22\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Got map stage job 54 (show at cell83.sc:1) with 6 output partitions\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Final stage: ShuffleMapStage 86 (show at cell83.sc:1)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[187] at show at cell83.sc:1), which has no missing parents\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.5 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on ubuntu:43381 (size: 8.0 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[187] at show at cell83.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Adding task set 86.0 with 6 tasks resource profile 0\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 154) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 155) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 156) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 157) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 4.0 in stage 86.0 (TID 158) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 5.0 in stage 86.0 (TID 159) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO Executor: Running task 4.0 in stage 86.0 (TID 158)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 5.0 in stage 86.0 (TID 159)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 3.0 in stage 86.0 (TID 157)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 0.0 in stage 86.0 (TID 154)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 1.0 in stage 86.0 (TID 155)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 2.0 in stage 86.0 (TID 156)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_52_piece0 on ubuntu:43381 in memory (size: 11.6 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 4.0 in stage 86.0 (TID 158). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 2.0 in stage 86.0 (TID 156). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 3.0 in stage 86.0 (TID 157). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 4.0 in stage 86.0 (TID 158) in 31 ms on ubuntu (executor driver) (1/6)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_51_piece0 on ubuntu:43381 in memory (size: 11.2 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 1.0 in stage 86.0 (TID 155). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 156) in 34 ms on ubuntu (executor driver) (2/6)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 0.0 in stage 86.0 (TID 154). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 155) in 36 ms on ubuntu (executor driver) (3/6)\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 157) in 36 ms on ubuntu (executor driver) (4/6)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 5.0 in stage 86.0 (TID 159). 2338 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 154) in 37 ms on ubuntu (executor driver) (5/6)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_50_piece0 on ubuntu:43381 in memory (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 5.0 in stage 86.0 (TID 159) in 37 ms on ubuntu (executor driver) (6/6)\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:12 INFO DAGScheduler: ShuffleMapStage 86 (show at cell83.sc:1) finished in 0,043 s\n",
      "24/02/19 11:37:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/19 11:37:12 INFO DAGScheduler: running: HashSet()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: waiting: HashSet()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: failed: HashSet()\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_53_piece0 on ubuntu:43381 in memory (size: 13.0 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/02/19 11:37:12 INFO SparkContext: Starting job: show at cell83.sc:1\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Got job 55 (show at cell83.sc:1) with 1 output partitions\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Final stage: ResultStage 88 (show at cell83.sc:1)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[193] at show at cell83.sc:1), which has no missing parents\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 29.6 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on ubuntu:43381 (size: 12.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[193] at show at cell83.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 160) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/02/19 11:37:12 INFO Executor: Running task 0.0 in stage 88.0 (TID 160)\n",
      "24/02/19 11:37:12 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/02/19 11:37:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 0.0 in stage 88.0 (TID 160). 5083 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 160) in 16 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:12 INFO DAGScheduler: ResultStage 88 (show at cell83.sc:1) finished in 0,022 s\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Job 55 finished: show at cell83.sc:1, took 0,028303 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.where($\"row_number\" === 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aea680ad-9eb7-443d-bc29-b54a343b2141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/19 11:37:12 INFO DAGScheduler: Registering RDD 196 (show at cell84.sc:1) as input to shuffle 23\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Got map stage job 56 (show at cell84.sc:1) with 6 output partitions\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Final stage: ShuffleMapStage 89 (show at cell84.sc:1)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[196] at show at cell84.sc:1), which has no missing parents\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 9.2 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on ubuntu:43381 (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[196] at show at cell84.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Adding task set 89.0 with 6 tasks resource profile 0\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 161) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 162) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 163) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7992 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 164) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 4.0 in stage 89.0 (TID 165) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 5.0 in stage 89.0 (TID 166) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7984 bytes) \n",
      "24/02/19 11:37:12 INFO Executor: Running task 3.0 in stage 89.0 (TID 164)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 1.0 in stage 89.0 (TID 162)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 5.0 in stage 89.0 (TID 166)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 2.0 in stage 89.0 (TID 163)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 4.0 in stage 89.0 (TID 165)\n",
      "24/02/19 11:37:12 INFO Executor: Running task 0.0 in stage 89.0 (TID 161)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 2.0 in stage 89.0 (TID 163). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 163) in 12 ms on ubuntu (executor driver) (1/6)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 5.0 in stage 89.0 (TID 166). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 3.0 in stage 89.0 (TID 164). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 4.0 in stage 89.0 (TID 165). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 5.0 in stage 89.0 (TID 166) in 12 ms on ubuntu (executor driver) (2/6)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 0.0 in stage 89.0 (TID 161). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 164) in 13 ms on ubuntu (executor driver) (3/6)\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 1.0 in stage 89.0 (TID 162). 1914 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 161) in 14 ms on ubuntu (executor driver) (4/6)\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 4.0 in stage 89.0 (TID 165) in 14 ms on ubuntu (executor driver) (5/6)\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 162) in 15 ms on ubuntu (executor driver) (6/6)\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:12 INFO DAGScheduler: ShuffleMapStage 89 (show at cell84.sc:1) finished in 0,019 s\n",
      "24/02/19 11:37:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/02/19 11:37:12 INFO DAGScheduler: running: HashSet()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: waiting: HashSet()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: failed: HashSet()\n",
      "24/02/19 11:37:12 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/02/19 11:37:12 INFO SparkContext: Starting job: show at cell84.sc:1\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Got job 57 (show at cell84.sc:1) with 1 output partitions\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Final stage: ResultStage 91 (show at cell84.sc:1)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[201] at show at cell84.sc:1), which has no missing parents\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 28.8 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_55_piece0 on ubuntu:43381 in memory (size: 12.3 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on ubuntu:43381 (size: 12.1 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1580\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[201] at show at cell84.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_54_piece0 on ubuntu:43381 in memory (size: 8.0 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "24/02/19 11:37:12 INFO BlockManagerInfo: Removed broadcast_56_piece0 on ubuntu:43381 in memory (size: 4.7 KiB, free: 4.5 GiB)\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 167) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/02/19 11:37:12 INFO Executor: Running task 0.0 in stage 91.0 (TID 167)\n",
      "24/02/19 11:37:12 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/02/19 11:37:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/02/19 11:37:12 INFO Executor: Finished task 0.0 in stage 91.0 (TID 167). 4840 bytes result sent to driver\n",
      "24/02/19 11:37:12 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 167) in 15 ms on ubuntu (executor driver) (1/1)\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "24/02/19 11:37:12 INFO DAGScheduler: ResultStage 91 (show at cell84.sc:1) finished in 0,035 s\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/02/19 11:37:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "24/02/19 11:37:12 INFO DAGScheduler: Job 57 finished: show at cell84.sc:1, took 0,039410 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|revenue2|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|    NULL|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|     153|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|     153|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|    NULL|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|     300|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|     300|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.withColumn(\"revenue2\", nth_value($\"revenue\", 2).over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c7042-3b2c-4d32-a8cb-8aa8e6c5d252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
