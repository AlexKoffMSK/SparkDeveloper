{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6568ca62-c9d6-4893-96b5-9e8025fa9147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.0`\n",
    "import $ivy.`org.postgresql:postgresql:42.7.2`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a25d85-2ecc-41a9-877c-ba49f3056892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e0ef85-6403-40fe-99c3-a308d9699219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "24/03/13 20:48:13 INFO SparkContext: Running Spark version 3.5.0\n",
      "24/03/13 20:48:13 INFO SparkContext: OS info Linux, 6.5.0-25-generic, amd64\n",
      "24/03/13 20:48:13 INFO SparkContext: Java version 11.0.22\n",
      "24/03/13 20:48:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/13 20:48:14 INFO ResourceUtils: ==============================================================\n",
      "24/03/13 20:48:14 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/03/13 20:48:14 INFO ResourceUtils: ==============================================================\n",
      "24/03/13 20:48:14 INFO SparkContext: Submitted application: JDBC Data Source\n",
      "24/03/13 20:48:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/03/13 20:48:14 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/03/13 20:48:14 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/03/13 20:48:14 INFO SecurityManager: Changing view acls to: vadim\n",
      "24/03/13 20:48:14 INFO SecurityManager: Changing modify acls to: vadim\n",
      "24/03/13 20:48:14 INFO SecurityManager: Changing view acls groups to: \n",
      "24/03/13 20:48:14 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/03/13 20:48:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vadim; groups with view permissions: EMPTY; users with modify permissions: vadim; groups with modify permissions: EMPTY\n",
      "24/03/13 20:48:14 INFO Utils: Successfully started service 'sparkDriver' on port 45783.\n",
      "24/03/13 20:48:14 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/03/13 20:48:14 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/03/13 20:48:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/03/13 20:48:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/03/13 20:48:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/03/13 20:48:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-63861a1e-e2dc-4425-af55-75f32897f7a7\n",
      "24/03/13 20:48:14 INFO MemoryStore: MemoryStore started with capacity 4.5 GiB\n",
      "24/03/13 20:48:14 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/03/13 20:48:14 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/03/13 20:48:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/13 20:48:14 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "24/03/13 20:48:14 INFO Executor: Starting executor ID driver on host ubuntu\n",
      "24/03/13 20:48:14 INFO Executor: OS info Linux, 6.5.0-25-generic, amd64\n",
      "24/03/13 20:48:14 INFO Executor: Java version 11.0.22\n",
      "24/03/13 20:48:14 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "24/03/13 20:48:14 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@239ab508 for default.\n",
      "24/03/13 20:48:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45869.\n",
      "24/03/13 20:48:14 INFO NettyBlockTransferService: Server created on ubuntu:45869\n",
      "24/03/13 20:48:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/03/13 20:48:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ubuntu, 45869, None)\n",
      "24/03/13 20:48:14 INFO BlockManagerMasterEndpoint: Registering block manager ubuntu:45869 with 4.5 GiB RAM, BlockManagerId(driver, ubuntu, 45869, None)\n",
      "24/03/13 20:48:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ubuntu, 45869, None)\n",
      "24/03/13 20:48:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ubuntu, 45869, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@780d647b\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"JDBC Data Source\")\n",
    "                .config(\"spark.driver.memory\", \"16g\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe90f98-4664-4c71-8774-680c686bb180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdriver\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"org.postgresql.Driver\"\u001b[39m\n",
       "\u001b[36murl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"jdbc:postgresql://localhost:5432/spark\"\u001b[39m\n",
       "\u001b[36muser\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m\n",
       "\u001b[36mpassword\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val driver = \"org.postgresql.Driver\"\n",
    "val url = \"jdbc:postgresql://localhost:5432/spark\"\n",
    "val user = \"postgres\"\n",
    "val password = \"postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b2b635-d31f-4902-b88b-9b4b594e3781",
   "metadata": {},
   "source": [
    "### Партиционирование по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a44c76-8669-43ca-a7f3-044edd1f26db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/03/13 20:48:16 INFO SharedState: Warehouse path is 'file:/home/vadim/workspace/Spark/JDBC/spark-warehouse'.\n",
      "24/03/13 20:48:17 INFO JDBCRelation: Number of partitions: 10, WHERE clauses of these partitions: \"emp_no\" < 59008 or \"emp_no\" is null, \"emp_no\" >= 59008 AND \"emp_no\" < 108006, \"emp_no\" >= 108006 AND \"emp_no\" < 157004, \"emp_no\" >= 157004 AND \"emp_no\" < 206002, \"emp_no\" >= 206002 AND \"emp_no\" < 255000, \"emp_no\" >= 255000 AND \"emp_no\" < 303998, \"emp_no\" >= 303998 AND \"emp_no\" < 352996, \"emp_no\" >= 352996 AND \"emp_no\" < 401994, \"emp_no\" >= 401994 AND \"emp_no\" < 450992, \"emp_no\" >= 450992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf102\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [emp_no: int, birth_date: date ... 4 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df102 = spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", user)\n",
    "    .option(\"password\", password)\n",
    "    .option(\"dbtable\", \"public.employees\")\n",
    "    .option(\"partitionColumn\", \"emp_no\")\n",
    "    .option(\"lowerBound\", \"10010\")\n",
    "    .option(\"upperBound\", \"499990\")\n",
    "    .option(\"numPartitions\", \"10\")\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c891d7-9e95-428c-bc43-1f50023c0915",
   "metadata": {},
   "source": [
    "Number of partitions: 10\n",
    "\n",
    "WHERE clauses of these partitions: \n",
    "- \"emp_no\" < 59008 or \"emp_no\" is null\n",
    "- \"emp_no\" >= 59008 AND \"emp_no\" < 108006\n",
    "- \"emp_no\" >= 108006 AND \"emp_no\" < 157004\n",
    "- \"emp_no\" >= 157004 AND \"emp_no\" < 206002\n",
    "- \"emp_no\" >= 206002 AND \"emp_no\" < 255000\n",
    "- \"emp_no\" >= 255000 AND \"emp_no\" < 303998\n",
    "- \"emp_no\" >= 303998 AND \"emp_no\" < 352996\n",
    "- \"emp_no\" >= 352996 AND \"emp_no\" < 401994\n",
    "- \"emp_no\" >= 401994 AND \"emp_no\" < 450992\n",
    "- \"emp_no\" >= 450992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d925c6c-14e6-4236-b1ef-117dc286a987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:18 INFO CodeGenerator: Code generated in 160.106895 ms\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Registering RDD 2 (count at cell6.sc:1) as input to shuffle 0\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Got map stage job 0 (count at cell6.sc:1) with 10 output partitions\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at cell6.sc:1)\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at cell6.sc:1), which has no missing parents\n",
      "24/03/13 20:48:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ubuntu:45869 (size: 7.7 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at cell6.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
      "24/03/13 20:48:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks resource profile 0\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7568 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7571 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (ubuntu, executor driver, partition 6, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (ubuntu, executor driver, partition 7, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)\n",
      "24/03/13 20:48:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/03/13 20:48:19 INFO CodeGenerator: Code generated in 17.210956 ms\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (ubuntu, executor driver, partition 8, PROCESS_LOCAL, 7572 bytes) \n",
      "24/03/13 20:48:19 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2011 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (ubuntu, executor driver, partition 9, PROCESS_LOCAL, 7550 bytes) \n",
      "24/03/13 20:48:19 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 250 ms on ubuntu (executor driver) (1/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 255 ms on ubuntu (executor driver) (2/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 263 ms on ubuntu (executor driver) (3/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 282 ms on ubuntu (executor driver) (4/10)\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 270 ms on ubuntu (executor driver) (5/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 276 ms on ubuntu (executor driver) (6/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 270 ms on ubuntu (executor driver) (7/10)\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 270 ms on ubuntu (executor driver) (8/10)\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 52 ms on ubuntu (executor driver) (9/10)\n",
      "24/03/13 20:48:19 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 59 ms on ubuntu (executor driver) (10/10)\n",
      "24/03/13 20:48:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:19 INFO DAGScheduler: ShuffleMapStage 0 (count at cell6.sc:1) finished in 0,534 s\n",
      "24/03/13 20:48:19 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/13 20:48:19 INFO DAGScheduler: running: HashSet()\n",
      "24/03/13 20:48:19 INFO DAGScheduler: waiting: HashSet()\n",
      "24/03/13 20:48:19 INFO DAGScheduler: failed: HashSet()\n",
      "24/03/13 20:48:19 INFO CodeGenerator: Code generated in 12.852864 ms\n",
      "24/03/13 20:48:19 INFO SparkContext: Starting job: count at cell6.sc:1\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Got job 1 (count at cell6.sc:1) with 1 output partitions\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Final stage: ResultStage 2 (count at cell6.sc:1)\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at cell6.sc:1), which has no missing parents\n",
      "24/03/13 20:48:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ubuntu:45869 (size: 6.1 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at cell6.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/13 20:48:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/03/13 20:48:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)\n",
      "24/03/13 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 10 (600.0 B) non-empty blocks including 10 (600.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/03/13 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "24/03/13 20:48:19 INFO CodeGenerator: Code generated in 9.829781 ms\n",
      "24/03/13 20:48:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 4127 bytes result sent to driver\n",
      "24/03/13 20:48:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 84 ms on ubuntu (executor driver) (1/1)\n",
      "24/03/13 20:48:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:19 INFO DAGScheduler: ResultStage 2 (count at cell6.sc:1) finished in 0,102 s\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/13 20:48:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "24/03/13 20:48:19 INFO DAGScheduler: Job 1 finished: count at cell6.sc:1, took 0,122415 s\n",
      "24/03/13 20:48:19 INFO CodeGenerator: Code generated in 14.766483 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 30003\n",
      "num partitions = 10\n"
     ]
    }
   ],
   "source": [
    "println(s\"count = ${df102.count()}\\nnum partitions = ${df102.rdd.getNumPartitions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f8bd49-d668-476a-a9b5-3861cca86ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:20 INFO SparkContext: Starting job: collect at cell7.sc:1\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Got job 2 (collect at cell7.sc:1) with 10 output partitions\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Final stage: ResultStage 3 (collect at cell7.sc:1)\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at mapPartitionsWithIndex at cell7.sc:1), which has no missing parents\n",
      "24/03/13 20:48:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.9 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ubuntu:45869 (size: 9.9 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:20 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at mapPartitionsWithIndex at cell7.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
      "24/03/13 20:48:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 10 tasks resource profile 0\n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7579 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 12) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7582 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 13) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 14) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 15) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 16) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 17) (ubuntu, executor driver, partition 6, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 18) (ubuntu, executor driver, partition 7, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 7.0 in stage 3.0 (TID 18)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 5.0 in stage 3.0 (TID 16)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 6.0 in stage 3.0 (TID 17)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 2.0 in stage 3.0 (TID 13)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 3.0 in stage 3.0 (TID 14)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 1.0 in stage 3.0 (TID 12)\n",
      "24/03/13 20:48:20 INFO Executor: Running task 4.0 in stage 3.0 (TID 15)\n",
      "24/03/13 20:48:20 INFO CodeGenerator: Code generated in 26.656795 ms\n",
      "24/03/13 20:48:20 INFO CodeGenerator: Code generated in 23.99364 ms\n",
      "24/03/13 20:48:20 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:20 INFO Executor: Finished task 6.0 in stage 3.0 (TID 17). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:20 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 19) (ubuntu, executor driver, partition 8, PROCESS_LOCAL, 7583 bytes) \n",
      "24/03/13 20:48:20 INFO Executor: Running task 8.0 in stage 3.0 (TID 19)\n",
      "24/03/13 20:48:20 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 17) in 463 ms on ubuntu (executor driver) (1/10)\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 2.0 in stage 3.0 (TID 13). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 20) (ubuntu, executor driver, partition 9, PROCESS_LOCAL, 7561 bytes) \n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 13) in 583 ms on ubuntu (executor driver) (2/10)\n",
      "24/03/13 20:48:21 INFO Executor: Running task 9.0 in stage 3.0 (TID 20)\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 7.0 in stage 3.0 (TID 18). 1492 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 18) in 592 ms on ubuntu (executor driver) (3/10)\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 3.0 in stage 3.0 (TID 14). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 14) in 656 ms on ubuntu (executor driver) (4/10)\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 1.0 in stage 3.0 (TID 12). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 718 ms on ubuntu (executor driver) (5/10)\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 9.0 in stage 3.0 (TID 20). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 4.0 in stage 3.0 (TID 15). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 12) in 720 ms on ubuntu (executor driver) (6/10)\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 5.0 in stage 3.0 (TID 16). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO Executor: Finished task 8.0 in stage 3.0 (TID 19). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 20) in 145 ms on ubuntu (executor driver) (7/10)\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 19) in 261 ms on ubuntu (executor driver) (8/10)\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 15) in 724 ms on ubuntu (executor driver) (9/10)\n",
      "24/03/13 20:48:21 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 16) in 724 ms on ubuntu (executor driver) (10/10)\n",
      "24/03/13 20:48:21 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:21 INFO DAGScheduler: ResultStage 3 (collect at cell7.sc:1) finished in 0,744 s\n",
      "24/03/13 20:48:21 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/13 20:48:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "24/03/13 20:48:21 INFO DAGScheduler: Job 2 finished: collect at cell7.sc:1, took 0,751313 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres7\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m0\u001b[39m, \u001b[32m4900\u001b[39m),\n",
       "  (\u001b[32m1\u001b[39m, \u001b[32m4900\u001b[39m),\n",
       "  (\u001b[32m2\u001b[39m, \u001b[32m203\u001b[39m),\n",
       "  (\u001b[32m3\u001b[39m, \u001b[32m601\u001b[39m),\n",
       "  (\u001b[32m4\u001b[39m, \u001b[32m4899\u001b[39m),\n",
       "  (\u001b[32m5\u001b[39m, \u001b[32m4500\u001b[39m),\n",
       "  (\u001b[32m6\u001b[39m, \u001b[32m0\u001b[39m),\n",
       "  (\u001b[32m7\u001b[39m, \u001b[32m200\u001b[39m),\n",
       "  (\u001b[32m8\u001b[39m, \u001b[32m4900\u001b[39m),\n",
       "  (\u001b[32m9\u001b[39m, \u001b[32m4900\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df102.rdd.mapPartitionsWithIndex { (p,i) => List((p, i.length)).iterator }.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8190f-732f-419c-bf8c-9cfd853500ff",
   "metadata": {},
   "source": [
    "Зададим в качестве *lowerBound* и *upperBound* произвольные значения (не min и max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efcb1c35-2404-4e60-847b-13f28f4797ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:21 INFO JDBCRelation: Number of partitions: 10, WHERE clauses of these partitions: \"emp_no\" < 23000 or \"emp_no\" is null, \"emp_no\" >= 23000 AND \"emp_no\" < 26000, \"emp_no\" >= 26000 AND \"emp_no\" < 29000, \"emp_no\" >= 29000 AND \"emp_no\" < 32000, \"emp_no\" >= 32000 AND \"emp_no\" < 35000, \"emp_no\" >= 35000 AND \"emp_no\" < 38000, \"emp_no\" >= 38000 AND \"emp_no\" < 41000, \"emp_no\" >= 41000 AND \"emp_no\" < 44000, \"emp_no\" >= 44000 AND \"emp_no\" < 47000, \"emp_no\" >= 47000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf103\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [emp_no: int, birth_date: date ... 4 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df103 = spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"driver\", driver)\n",
    "    .option(\"url\", url)\n",
    "    .option(\"user\", user)\n",
    "    .option(\"password\", password)\n",
    "    .option(\"dbtable\", \"public.employees\")\n",
    "    .option(\"partitionColumn\", \"emp_no\")\n",
    "    .option(\"lowerBound\", \"20000\")\n",
    "    .option(\"upperBound\", \"50000\")\n",
    "    .option(\"numPartitions\", \"10\")\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0090f-1776-4727-a8d1-73a7a72764f0",
   "metadata": {},
   "source": [
    "Number of partitions: 10\n",
    "\n",
    "WHERE clauses of these partitions:\n",
    "- \"emp_no\" < 23000 or \"emp_no\" is null\n",
    "- \"emp_no\" >= 23000 AND \"emp_no\" < 26000\n",
    "- \"emp_no\" >= 26000 AND \"emp_no\" < 29000\n",
    "- \"emp_no\" >= 29000 AND \"emp_no\" < 32000\n",
    "- \"emp_no\" >= 32000 AND \"emp_no\" < 35000\n",
    "- \"emp_no\" >= 35000 AND \"emp_no\" < 38000\n",
    "- \"emp_no\" >= 38000 AND \"emp_no\" < 41000\n",
    "- \"emp_no\" >= 41000 AND \"emp_no\" < 44000\n",
    "- \"emp_no\" >= 44000 AND \"emp_no\" < 47000\n",
    "- \"emp_no\" >= 47000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8396c33-6ee1-4052-84af-88389572467e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:22 INFO DAGScheduler: Registering RDD 14 (count at cell9.sc:1) as input to shuffle 1\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Got map stage job 3 (count at cell9.sc:1) with 10 output partitions\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at cell9.sc:1)\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at count at cell9.sc:1), which has no missing parents\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ubuntu:45869 (size: 7.7 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at count at cell9.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 10 tasks resource profile 0\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 21) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7568 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 22) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 23) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 24) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ubuntu:45869 in memory (size: 7.7 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 25) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 26) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 27) (ubuntu, executor driver, partition 6, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 28) (ubuntu, executor driver, partition 7, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO Executor: Running task 2.0 in stage 4.0 (TID 23)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 6.0 in stage 4.0 (TID 27)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 1.0 in stage 4.0 (TID 22)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 21)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 4.0 in stage 4.0 (TID 25)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 7.0 in stage 4.0 (TID 28)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 5.0 in stage 4.0 (TID 26)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 3.0 in stage 4.0 (TID 24)\n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ubuntu:45869 in memory (size: 6.1 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ubuntu:45869 in memory (size: 9.9 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 7.0 in stage 4.0 (TID 28). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 4.0 in stage 4.0 (TID 25). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 29) (ubuntu, executor driver, partition 8, PROCESS_LOCAL, 7570 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 28) in 55 ms on ubuntu (executor driver) (1/10)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 8.0 in stage 4.0 (TID 29)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 2.0 in stage 4.0 (TID 23). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 21). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 30) (ubuntu, executor driver, partition 9, PROCESS_LOCAL, 7549 bytes) \n",
      "24/03/13 20:48:22 INFO Executor: Running task 9.0 in stage 4.0 (TID 30)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 25) in 71 ms on ubuntu (executor driver) (2/10)\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 3.0 in stage 4.0 (TID 24). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 6.0 in stage 4.0 (TID 27). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 23) in 82 ms on ubuntu (executor driver) (3/10)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 5.0 in stage 4.0 (TID 26). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 21) in 91 ms on ubuntu (executor driver) (4/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 24) in 92 ms on ubuntu (executor driver) (5/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 26) in 92 ms on ubuntu (executor driver) (6/10)\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 1.0 in stage 4.0 (TID 22). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 8.0 in stage 4.0 (TID 29). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 22) in 100 ms on ubuntu (executor driver) (7/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 29) in 48 ms on ubuntu (executor driver) (8/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 27) in 105 ms on ubuntu (executor driver) (9/10)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 9.0 in stage 4.0 (TID 30). 1968 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 30) in 63 ms on ubuntu (executor driver) (10/10)\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:22 INFO DAGScheduler: ShuffleMapStage 4 (count at cell9.sc:1) finished in 0,154 s\n",
      "24/03/13 20:48:22 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/03/13 20:48:22 INFO DAGScheduler: running: HashSet()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: waiting: HashSet()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: failed: HashSet()\n",
      "24/03/13 20:48:22 INFO SparkContext: Starting job: count at cell9.sc:1\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Got job 4 (count at cell9.sc:1) with 1 output partitions\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Final stage: ResultStage 6 (count at cell9.sc:1)\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[17] at count at cell9.sc:1), which has no missing parents\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ubuntu:45869 (size: 6.1 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[17] at count at cell9.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 31) (ubuntu, executor driver, partition 0, NODE_LOCAL, 7695 bytes) \n",
      "24/03/13 20:48:22 INFO Executor: Running task 0.0 in stage 6.0 (TID 31)\n",
      "24/03/13 20:48:22 INFO ShuffleBlockFetcherIterator: Getting 10 (600.0 B) non-empty blocks including 10 (600.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/03/13 20:48:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 0.0 in stage 6.0 (TID 31). 4084 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 31) in 14 ms on ubuntu (executor driver) (1/1)\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:22 INFO DAGScheduler: ResultStage 6 (count at cell9.sc:1) finished in 0,030 s\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Job 4 finished: count at cell9.sc:1, took 0,036482 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 30003\n",
      "num partitions = 10\n"
     ]
    }
   ],
   "source": [
    "println(s\"count = ${df103.count()}\\nnum partitions = ${df103.rdd.getNumPartitions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8363c0e-331f-466c-8871-a2816bdcff7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 20:48:22 INFO SparkContext: Starting job: collect at cell10.sc:1\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Got job 5 (collect at cell10.sc:1) with 10 output partitions\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Final stage: ResultStage 7 (collect at cell10.sc:1)\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at mapPartitionsWithIndex at cell10.sc:1), which has no missing parents\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 21.9 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ubuntu:45869 (size: 9.9 KiB, free: 4.5 GiB)\n",
      "24/03/13 20:48:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at mapPartitionsWithIndex at cell10.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 10 tasks resource profile 0\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 32) (ubuntu, executor driver, partition 0, PROCESS_LOCAL, 7579 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 33) (ubuntu, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 34) (ubuntu, executor driver, partition 2, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 35) (ubuntu, executor driver, partition 3, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 36) (ubuntu, executor driver, partition 4, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 37) (ubuntu, executor driver, partition 5, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 38) (ubuntu, executor driver, partition 6, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 39) (ubuntu, executor driver, partition 7, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO Executor: Running task 0.0 in stage 7.0 (TID 32)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 1.0 in stage 7.0 (TID 33)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 6.0 in stage 7.0 (TID 38)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 7.0 in stage 7.0 (TID 39)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 5.0 in stage 7.0 (TID 37)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 4.0 in stage 7.0 (TID 36)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 2.0 in stage 7.0 (TID 34)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 3.0 in stage 7.0 (TID 35)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 1.0 in stage 7.0 (TID 33). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 40) (ubuntu, executor driver, partition 8, PROCESS_LOCAL, 7581 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 33) in 58 ms on ubuntu (executor driver) (1/10)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 8.0 in stage 7.0 (TID 40)\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 7.0 in stage 7.0 (TID 39). 1492 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 41) (ubuntu, executor driver, partition 9, PROCESS_LOCAL, 7560 bytes) \n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 39) in 57 ms on ubuntu (executor driver) (2/10)\n",
      "24/03/13 20:48:22 INFO Executor: Running task 9.0 in stage 7.0 (TID 41)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 6.0 in stage 7.0 (TID 38). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 38) in 68 ms on ubuntu (executor driver) (3/10)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 2.0 in stage 7.0 (TID 34). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 3.0 in stage 7.0 (TID 35). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 4.0 in stage 7.0 (TID 36). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 0.0 in stage 7.0 (TID 32). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 34) in 86 ms on ubuntu (executor driver) (4/10)\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 5.0 in stage 7.0 (TID 37). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 35) in 89 ms on ubuntu (executor driver) (5/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 37) in 93 ms on ubuntu (executor driver) (6/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 32) in 99 ms on ubuntu (executor driver) (7/10)\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 36) in 96 ms on ubuntu (executor driver) (8/10)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 8.0 in stage 7.0 (TID 40). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 40) in 56 ms on ubuntu (executor driver) (9/10)\n",
      "24/03/13 20:48:22 INFO JDBCRDD: closed connection\n",
      "24/03/13 20:48:22 INFO Executor: Finished task 9.0 in stage 7.0 (TID 41). 1449 bytes result sent to driver\n",
      "24/03/13 20:48:22 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 41) in 139 ms on ubuntu (executor driver) (10/10)\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "24/03/13 20:48:22 INFO DAGScheduler: ResultStage 7 (collect at cell10.sc:1) finished in 0,214 s\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/03/13 20:48:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "24/03/13 20:48:22 INFO DAGScheduler: Job 5 finished: collect at cell10.sc:1, took 0,221542 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres10\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m0\u001b[39m, \u001b[32m1299\u001b[39m),\n",
       "  (\u001b[32m1\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m2\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m3\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m4\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m5\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m6\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m7\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m8\u001b[39m, \u001b[32m300\u001b[39m),\n",
       "  (\u001b[32m9\u001b[39m, \u001b[32m26304\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df103.rdd.mapPartitionsWithIndex { (p,i) => List((p, i.length)).iterator }.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
