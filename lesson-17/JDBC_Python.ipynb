{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3eae9-38ea-40bf-bb2b-f3ba0eb393c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bb7f1-1649-4419-be8a-2cab7ba0b3f2",
   "metadata": {},
   "source": [
    "Создаём SparkSession. Добавляем путь к драйверу JDBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a24d33-f85f-4ba6-95ae-61901ddacac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"JDBC Data Source\")\n",
    "        .config(\"spark.jars\", \"jars/postgresql-42.7.2.jar\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d0b6e-76bb-421c-920d-02cb84e72411",
   "metadata": {},
   "source": [
    "Задаём свойства подключения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d93afc-be0e-420d-af36-4247fdf8cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"org.postgresql.Driver\"\n",
    "url = \"jdbc:postgresql://localhost:5432/spark\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e48b3-e72b-48ce-90fd-5e66f3cc117c",
   "metadata": {},
   "source": [
    "## Чтение таблицы целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533923fc-54c6-4bdd-b324-32c6baf9dce9",
   "metadata": {},
   "source": [
    "### Вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713126df-fb47-451a-8c14-36afe87ae5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees\") \\\n",
    "    .load()\n",
    "\n",
    "employees_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390bf25-1579-47dc-a8d5-0f6982660057",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108bedf-5ec3-4ff7-9706-d48c293e8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc472-968d-4e5f-aa08-d0593bc9b877",
   "metadata": {},
   "source": [
    "### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d45f91-da3b-488f-9021-4fd4ae5831dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBPARAMS = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": driver\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03b075-33a3-4358-99b5-fa0f40103aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ca1ac-5e58-4c85-989e-45cd14e6d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876be6b8-58b1-4d63-8790-d980253351ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c21403-9cfb-4c5f-a3be-fde85d3d7f87",
   "metadata": {},
   "source": [
    "Проверим количество партиций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0645e84-b0a1-4570-a6b2-dfbcef91667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88633689-14d4-4dac-9693-936a1ee13db0",
   "metadata": {},
   "source": [
    "## Как распараллелить чтение?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a05e8-9844-4e11-817e-cea50cece673",
   "metadata": {},
   "source": [
    "### Партиционирование по столбцам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabc184-42ed-4ebb-960f-daf600d91d37",
   "metadata": {},
   "source": [
    "Добавим количество партиций к параметрам чтения таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f86f6-08e8-4b6d-8464-216814fa6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df101 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, numPartitions=10)\n",
    "\n",
    "print(\"count = \", df101.count())\n",
    "print(\"num partitions = \", df101.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f57bc1-dd8a-40f1-af8d-f49c6c6e0c94",
   "metadata": {},
   "source": [
    "Количество партиций не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80da1c8-5d28-44ba-a3dd-68aec3a7a4d9",
   "metadata": {},
   "source": [
    "Узнаем минимальное и максимальное значения столбца *emp_no*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b053c-f203-4a84-8639-8a9857cab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(min(col(\"emp_no\")), max(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181e231-5e06-42e2-b960-286c99b84514",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_emp_no = df.agg(min(col(\"emp_no\"))).collect()[0][0]\n",
    "max_emp_no = df.agg(max(col(\"emp_no\"))).collect()[0][0]\n",
    "\n",
    "print(\"min = \", min_emp_no, \"\\nmax = \", max_emp_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af774fc1-af16-4b3c-bbe1-caba23ed49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df102 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS,\n",
    "                        column=\"emp_no\", lowerBound = min_emp_no, upperBound = max_emp_no, numPartitions=10)\n",
    "\n",
    "print(\"count = \", df102.count())\n",
    "print(\"num partitions = \", df102.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984c9db-4dce-4266-9feb-b874960c62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df102.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa7a71-d146-4493-8ff7-43a335500c2a",
   "metadata": {},
   "source": [
    "Посмотрим сколько записей попало в каждую партицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed3b02-4fd1-41c1-b9b0-89b44decd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df102.rdd.foreachPartition(lambda p: print(\"Partition count = \", len(list(p))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5bee1-123c-417d-9ab5-1f937c0772d6",
   "metadata": {},
   "source": [
    "Это также можно получить другим способом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463b5ea-729c-41ae-ac0e-295808a57d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = df102.rdd.mapPartitionsWithIndex(lambda p, i: (p, len(list(i)))).collect()\n",
    "list(zip(pl[::2], pl[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbd85b-1cc4-4a89-bbeb-71538e7907a5",
   "metadata": {},
   "source": [
    "Зададим в качестве *lowerBound* и *upperBound* произвольные значения (не min и max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259f552-c19d-4f1d-a5de-1f16ff7dbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df103 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees\") \\\n",
    "    .option(\"partitionColumn\", \"emp_no\") \\\n",
    "    .option(\"lowerBound\", \"20000\") \\\n",
    "    .option(\"upperBound\", \"50000\") \\\n",
    "    .option(\"numPartitions\", \"10\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"count = \", df103.count())\n",
    "print(\"num partitions = \", df103.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba4673-609d-4992-9315-92e00f32608b",
   "metadata": {},
   "source": [
    "Посмотрим сколько теперь записей попало в каждую партицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4bd7b-2e72-45ff-9e87-ebd934e585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2 = df103.rdd.mapPartitionsWithIndex(lambda p, i: (p, len(list(i)))).collect()\n",
    "list(zip(pl2[::2], pl2[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136125f9-c347-4dae-a943-fb2b7f07b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df103.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589186e0-7610-4cd0-9616-d417f4373dd1",
   "metadata": {},
   "source": [
    "### Партиционирование по предикатам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1c337-deee-4174-992d-ba289fb6af8a",
   "metadata": {},
   "source": [
    "### Пример 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f807e-d7e8-4bb9-9078-86e097871e8b",
   "metadata": {},
   "source": [
    "Опредилим **два** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c972b0-a975-4a83-b36f-7ad0fb79270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [\"gender = 'M'\", \"gender = 'F'\"]\n",
    "\n",
    "df_pred = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred)\n",
    "\n",
    "print(\"count = \", df_pred.count())\n",
    "print(\"num partitions = \", df_pred.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da8606-665e-49aa-bbe7-941ae4bae4c4",
   "metadata": {},
   "source": [
    "Опредилим **один** предиката по одному значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77855569-49cd-41eb-8e74-26e763d138e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = [\"gender = 'F'\"]\n",
    "\n",
    "df_pred1 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred1)\n",
    "\n",
    "print(\"count = \", df_pred1.count())\n",
    "print(\"num partitions = \", df_pred1.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e15ad-f9e9-496f-954a-6fe695d34305",
   "metadata": {},
   "source": [
    "Опредилим **три** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fb889-6910-4f21-a1c5-7e8f5ec0d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = [\"gender = 'F'\", \"gender = 'M'\", \"gender = 'M'\"]\n",
    "\n",
    "df_pred3 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred3)\n",
    "\n",
    "print(\"count = \", df_pred3.count())\n",
    "print(\"num partitions = \", df_pred3.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f6bec-3e12-4c84-92c9-ae944d283f7d",
   "metadata": {},
   "source": [
    "Опредилим **четыре** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e31949-df44-43fc-85f7-d03e791df04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = [\"gender = 'F'\", \"gender = 'F'\", \"gender = 'M'\", \"gender = 'M'\"]\n",
    "\n",
    "df_pred4 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred4)\n",
    "\n",
    "print(\"count = \", df_pred4.count())\n",
    "print(\"num partitions = \", df_pred4.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2d3b9-ed24-4d7b-af6a-542b02010aab",
   "metadata": {},
   "source": [
    "Посмотрим сколько записей для каждого значения столбца *gender* было в исходной таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed3d76-26e2-4c56-8231-4bfd850004d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282af4c-dbdf-4d1d-98b9-bbd4e6fdeb3f",
   "metadata": {},
   "source": [
    "Сравним с количеством записей при применении трёх и четырёх предикатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5c54c-63c4-46c5-9501-8524f6b5455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred3.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b5f80-243a-4396-a907-0bfe3a57162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred4.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc51989-2137-4aa0-bdc6-2ef9e7673147",
   "metadata": {},
   "source": [
    "### Пример 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596b34-83d3-4a27-a75a-24f04e83957c",
   "metadata": {},
   "source": [
    "Определим **два** предиката по условиям на значения столбца *emp_no* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f107cc-d5ca-47ea-8531-74192817c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = [\"emp_no > 20000 and emp_no <= 50000\", \"emp_no >= 50000 and emp_no <= 100000\"]\n",
    "\n",
    "df_pred2 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred2)\n",
    "\n",
    "print(\"count = \", df_pred2.count())\n",
    "print(\"num partitions = \", df_pred2.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73bd83-dd96-4f59-94d6-f0b93a2940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e22f41-98d3-4974-9999-66dc33cb343e",
   "metadata": {},
   "source": [
    "Определим **один** предикат по условию на значения столбца *emp_no* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f604e53-ce36-46eb-94fd-87e8bae0a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred22 = [\"emp_no > 20000 and emp_no <= 50000\"]\n",
    "\n",
    "df_pred22 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred22)\n",
    "\n",
    "print(\"count = \", df_pred22.count())\n",
    "print(\"num partitions = \", df_pred22.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cbc17-1126-426c-8c2c-bce7b04457cd",
   "metadata": {},
   "source": [
    "## Фильтрация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9167cd-ef11-4203-a739-0538aa42efa6",
   "metadata": {},
   "source": [
    "Выполним запрос к базе на выборку значений из таблицы с условием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578941e3-3219-451e-9a3b-4f545b12af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"select * from public.employees where emp_no > 20000 and emp_no <= 50000\"\"\"\n",
    "\n",
    "dfq = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"query\", q) \\\n",
    "    .load()\n",
    "\n",
    "dfq.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a7dac-86bc-4730-aafe-a583b31be665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984111f-0675-46ed-a91c-addf3be33a66",
   "metadata": {},
   "source": [
    "## Соединения в базе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accb0b4-b895-4f85-b0ba-54dc569ea936",
   "metadata": {},
   "source": [
    "Выполним запрос к базе на выборку значений из соединения таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d29ff9-b3db-44da-a10e-20ce751d83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qj = \"\"\"select e.emp_no, birth_date, first_name, last_name, gender, hire_date, salary, from_date, to_date\n",
    "from employees e join salaries s on e.emp_no = s.emp_no\"\"\"\n",
    "\n",
    "dfj = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"query\", qj) \\\n",
    "    .load()\n",
    "\n",
    "dfj.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05627caa-afc5-447b-a747-bbe6472cd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865d95a-04a8-43a8-8f35-8562f0c6ef00",
   "metadata": {},
   "source": [
    "## Запись в таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1e6bb-0c80-425e-808b-7c70899dd1e3",
   "metadata": {},
   "source": [
    "Посмотрим на таблицу *employees*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d1c16-07de-4e6b-af94-89dec58f8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d9fb8-d69b-4c1b-854f-ff2f34ea59ff",
   "metadata": {},
   "source": [
    "Загрузим таблицу *salaries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52af57a-4b5d-4b3c-a82c-bce22c3a0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.salaries\") \\\n",
    "    .load()\n",
    "\n",
    "salaries_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165df63-e102-449f-878e-8ca17b70cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af1db4-cb4c-4b2b-bf7a-bab606db3ae8",
   "metadata": {},
   "source": [
    "Сделаем группировку по колонке *emp_no* и найдём максимальное значение колонки *salary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ace4d-6ce6-471a-8d6d-e71784fff159",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df = salaries_df.groupBy(col(\"emp_no\")).agg(max(col(\"salary\")).alias(\"max_salary\"))\n",
    "\n",
    "employees_salaries_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad45c36-b390-450c-b890-7436af2b4f53",
   "metadata": {},
   "source": [
    "Создадим новый Dataframe как результат соединения *employees_df* и агрегированного *salaries_df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c68c73-9ad1-4b6c-a001-3e223d9764b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df = employees_df.join(employees_salaries_df, \"emp_no\")\n",
    "\n",
    "employees_salaries_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca3454-0902-4063-9ff2-a130906a5e1b",
   "metadata": {},
   "source": [
    "Сохраним новый Dataframe в таблицу в базе. Таблицы с таким именем в базе не было. Она будет создана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e03d5-7f0c-420f-b743-437c27145a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a6b6c-153a-448d-a65d-cff200cc3e01",
   "metadata": {},
   "source": [
    "Если таблица с таким именем существовала в базе, то при сохранении надо использовать режим *overwrite*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94655e73-5684-439d-94c5-37c7e688a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .option(\"truncate\", \"true\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4340a-65bf-4e3b-99d1-b9f94f97edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .load() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c39cda-6e7e-4ecc-8167-8ea03069c5ee",
   "metadata": {},
   "source": [
    "Если использовать режим *append* содержимое Dataframe будет добавлено в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def5b68-c6b9-433b-8411-c298430de648",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d493c-9d24-4814-80ca-4a955e4b4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .load() \\\n",
    "    .count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
